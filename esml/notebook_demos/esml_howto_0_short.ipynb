{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3612jvsc74a57bd03fec2c5a411dce07235ef28c8752b6cecf1f94423de7e7c24e62fc38b1bc47de",
   "display_name": "Python 3.6.12 64-bit ('azure_automl': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# ESML - accelerator: Quick DEMO\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "![](../images/split_gold_and_train_automl_small.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"../common/\"))  # NOQA: E402\n",
    "from esml import ESMLDataset, ESMLProject\n",
    "p = ESMLProject() # Will search in ROOT for your copied SETTINGS folder '../../../settings', you should copy template settings from '../settings'\n",
    "#p = ESMLProject(True) # Demo settings, will search in internal TEMPLATE SETTINGS folder '../settings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training\n\n - ds01_diabetes\nmaster/1_projects/project002/03_diabetes_model_reg/train/ds01_diabetes/in/dev/2020/01/01/\nmaster/1_projects/project002/03_diabetes_model_reg/train/ds01_diabetes/out/bronze/dev/\nmaster/1_projects/project002/03_diabetes_model_reg/train/ds01_diabetes/out/silver/dev/\n\n - ds02_other\nmaster/1_projects/project002/03_diabetes_model_reg/train/ds02_other/in/dev/2020/01/01/\nmaster/1_projects/project002/03_diabetes_model_reg/train/ds02_other/out/bronze/dev/\nmaster/1_projects/project002/03_diabetes_model_reg/train/ds02_other/out/silver/dev/\nTraining GOLD \n\nmaster/1_projects/project002/03_diabetes_model_reg/train/gold/dev/\n \n\nENVIRONMENT - DEV, TEST, or PROD?\nACTIVE ENVIRONMENT = dev\nACTIVE subscription = ca0a8c40-b06a-4e4e-8434-63c03a1dee34\n- MSFT-WEU-EAP_PROJECT02_AI-DEV-RG\n- msft-weu-DEV-eap-proj02_ai-amls\n- westeurope\n- MSFT-WEU-EAP_CMN_AI-DEV-RG\n- msft-weu-dev-cmnai-vnet\n- msft-weu-dev-cmnai-sn-aml\n"
     ]
    }
   ],
   "source": [
    "#p.dev_test_prod = \"dev\"\n",
    "p.describe()"
   ]
  },
  {
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "auth = InteractiveLoginAuthentication(tenant_id = p.tenant)\n",
    "ws = Workspace.get(name = p.workspace_name,subscription_id = p.subscription_id,resource_group = p.resource_group,auth=auth)\n",
    "ws.write_config(path=\".\", file_name=\"../../ws_config.json\")\n",
    "\n",
    "ws = Workspace.from_config(\"../ws_config.json\") # Reads config.json "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 2) ESML will Automap and Autoregister Azure ML Datasets - IN, SILVER, BRONZE, GOLD\n",
    "- `Automap` and `Autoregister` Azure ML Datasets as: `IN, SILVER, BRONZE, GOLD`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'msft-weu-DEV-eap-proj02_ai-amls'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "ws, config_name = p.authenticate_workspace_and_write_config()\n",
    "ws = p.get_workspace_from_config()\n",
    "ws.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Are we in R&D state (no dataset versioning) = False\n"
     ]
    }
   ],
   "source": [
    "print(\"Are we in R&D state (no dataset versioning) = {}\".format(p.rnd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using GEN2 as Datastore\n",
      "Unregister Azure ML dataset for ESML dataset ds01_diabetes\n",
      "- IN name: M03_ds01_diabetes_IN_CSV\n",
      "- Bronze name: M03_ds01_diabetes_BRONZE\n",
      "- Silver name: M03_ds01_diabetes_SILVER\n",
      "Unregister Azure ML dataset for ESML dataset ds02_other\n",
      "- IN name: M03_ds02_other_IN_CSV\n",
      "- Bronze name: M03_ds02_other_BRONZE\n",
      "- Silver name: M03_ds02_other_SILVER\n",
      "Gold name: M03_GOLD \n"
     ]
    }
   ],
   "source": [
    "p.unregister_all_datasets(ws) # DEMO purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "...\n",
      "Using GEN2 as Datastore\n",
      "ds01_diabetes\n",
      "ds02_other\n",
      "\n",
      "####### Automap & Autoregister - SUCCESS!\n",
      "1) Auto mapped 2 ESML Dataset with registered Azure ML Datasets (potentially all 3: IN,BRONZE, SILVER) in Datastore project002lake \n",
      "\n",
      "Dataset 'ds01_diabetes' status:\n",
      " - IN_Folder_has_files\n",
      " - BRONZE_Folder_has_files\n",
      " - SILVER_Folder_has_files\n",
      "Dataset 'ds02_other' status:\n",
      " - IN_Folder_has_files\n",
      " - BRONZE_Folder_has_files\n",
      " - SILVER_Folder_has_files\n",
      "\n",
      "2) Registered each Dataset with suffixes (_IN_CSV, _BRONZE, _SILVER) \n",
      " Tip: Use ESMLProject.Datasets list or .DatasetByName(myDatasetName) to read/write\n",
      "#######\n"
     ]
    }
   ],
   "source": [
    "datastore = p.init(ws)"
   ]
  },
  {
   "source": [
    "# 3) IN->`BRONZE->SILVER`->Gold\n",
    "- Create dataset from PANDAS - Save to SILVER"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        AGE       SEX       BMI        BP        S1        S2        S3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         S4        S5        S6      Y  \n",
       "0 -0.002592  0.019908 -0.017646  151.0  \n",
       "1 -0.039493 -0.068330 -0.092204   75.0  \n",
       "2 -0.002592  0.002864 -0.025930  141.0  \n",
       "3  0.034309  0.022692 -0.009362  206.0  \n",
       "4 -0.002592 -0.031991 -0.046641  135.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AGE</th>\n      <th>SEX</th>\n      <th>BMI</th>\n      <th>BP</th>\n      <th>S1</th>\n      <th>S2</th>\n      <th>S3</th>\n      <th>S4</th>\n      <th>S5</th>\n      <th>S6</th>\n      <th>Y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.038076</td>\n      <td>0.050680</td>\n      <td>0.061696</td>\n      <td>0.021872</td>\n      <td>-0.044223</td>\n      <td>-0.034821</td>\n      <td>-0.043401</td>\n      <td>-0.002592</td>\n      <td>0.019908</td>\n      <td>-0.017646</td>\n      <td>151.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.001882</td>\n      <td>-0.044642</td>\n      <td>-0.051474</td>\n      <td>-0.026328</td>\n      <td>-0.008449</td>\n      <td>-0.019163</td>\n      <td>0.074412</td>\n      <td>-0.039493</td>\n      <td>-0.068330</td>\n      <td>-0.092204</td>\n      <td>75.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.085299</td>\n      <td>0.050680</td>\n      <td>0.044451</td>\n      <td>-0.005671</td>\n      <td>-0.045599</td>\n      <td>-0.034194</td>\n      <td>-0.032356</td>\n      <td>-0.002592</td>\n      <td>0.002864</td>\n      <td>-0.025930</td>\n      <td>141.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.089063</td>\n      <td>-0.044642</td>\n      <td>-0.011595</td>\n      <td>-0.036656</td>\n      <td>0.012191</td>\n      <td>0.024991</td>\n      <td>-0.036038</td>\n      <td>0.034309</td>\n      <td>0.022692</td>\n      <td>-0.009362</td>\n      <td>206.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.005383</td>\n      <td>-0.044642</td>\n      <td>-0.036385</td>\n      <td>0.021872</td>\n      <td>0.003935</td>\n      <td>0.015596</td>\n      <td>0.008142</td>\n      <td>-0.002592</td>\n      <td>-0.031991</td>\n      <td>-0.046641</td>\n      <td>135.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "import pandas as pd \n",
    "ds = p.DatasetByName(\"ds01_diabetes\")\n",
    "df = ds.Bronze.to_pandas_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "## 3) BRONZE-SILVER (EDIT rows & SAVE)\n",
    "- Test change rows, same structure = new version (and new file added)\n",
    "- Note: not earlier files in folder are removed. They are needed for other \"versions\". \n",
    "- Expected: For 3 files: New version, 997 rows: 2 older files=627 + 1 new file=370\n",
    "- Expected (if we delete OLD files): New version, with less rows. 370 instead of 997"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "442 185\n"
     ]
    }
   ],
   "source": [
    "df_filtered = df[df.AGE > 0.015]\n",
    "print(df.shape[0], df_filtered.shape[0])"
   ]
  },
  {
   "source": [
    "## 3a) Save `SILVER` ds01_diabetes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'M03_ds01_diabetes_SILVER'"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "aml_silver = p.save_silver(p.DatasetByName(\"ds01_diabetes\"),df_filtered)\n",
    "aml_silver.name"
   ]
  },
  {
   "source": [
    "### COMPARE `BRONZE vs SILVER`\n",
    "- Compare and validate the feature engineering"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Bronze: 442\nSilver: 185\n"
     ]
    }
   ],
   "source": [
    "ds01 = p.DatasetByName(\"ds01_diabetes\")\n",
    "bronze_rows = ds01.Bronze.to_pandas_dataframe().shape[0]\n",
    "silver_rows = ds01.Silver.to_pandas_dataframe().shape[0]\n",
    "\n",
    "print(\"Bronze: {}\".format(bronze_rows)) # Expected 442 rows\n",
    "print(\"Silver: {}\".format(silver_rows)) # Expected 185 rows (filtered)\n",
    "\n",
    "assert bronze_rows == 442,\"BRONZE Should have 442 rows to start with, but is {}\".format(bronze_rows)\n",
    "assert silver_rows == 185,\"SILVER should have 185 after filtering, but is {}\".format(silver_rows)"
   ]
  },
  {
   "source": [
    "## 3b) Save  `BRONZE â†’  SILVER` ds02_other"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'M03_ds02_other_SILVER'"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "df_edited = p.DatasetByName(\"ds02_other\").Silver.to_pandas_dataframe()\n",
    "ds02_silver = p.save_silver(p.DatasetByName(\"ds02_other\"),df_edited)\n",
    "ds02_silver.name"
   ]
  },
  {
   "source": [
    "## 3c) Merge all `SILVERS -> then save GOLD`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Diabetes shape:  (185, 11)\n(185, 19)\n"
     ]
    }
   ],
   "source": [
    "df_01 = ds01.Silver.to_pandas_dataframe()\n",
    "df_02 = ds02_silver.to_pandas_dataframe()\n",
    "df_gold1_join = df_01.join(df_02) # left join -> NULL on df_02\n",
    "print(\"Diabetes shape: \", df_01.shape)\n",
    "print(df_gold1_join.shape)"
   ]
  },
  {
   "source": [
    "# Save `GOLD` v1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(p.rnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.rnd=False # Allow versioning on DATASETS, to have lineage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_gold_v1 = p.save_gold(df_gold1_join)"
   ]
  },
  {
   "source": [
    "### 3c) Ops! \"faulty\" GOLD - too many features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(185, 19)\n"
     ]
    }
   ],
   "source": [
    "print(p.Gold.to_pandas_dataframe().shape) # 19 features...I want 11"
   ]
  },
  {
   "source": [
    "print(\"Are we in RnD phase? Or do we have 'versioning on datasets=ON'\")\n",
    "print(\"RnD phase = {}\".format(p.rnd))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Are we in RnD phase? Or do we have 'versioning on datasets=ON'\nRnD phase = False\n"
     ]
    }
   ]
  },
  {
   "source": [
    "# Save `GOLD` v2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets just go with features from ds01\n",
    "ds_gold_v1 = p.save_gold(df_01)"
   ]
  },
  {
   "source": [
    "# Get `GOLD` by version"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "gold_1 = p.get_gold_version(1)\n",
    "gold_1.to_pandas_dataframe().shape # (185, 19)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(185, 19)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(185, 11)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "gold_2 = p.get_gold_version(2)\n",
    "gold_2.to_pandas_dataframe().shape # (185, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(185, 11)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "p.Gold.to_pandas_dataframe().shape # Latest version (185, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01_filtered = df_01[df_01.AGE > 0.03807]\n",
    "ds_gold_v1 = p.save_gold(df_01_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(113, 11)"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "gold_2 = p.get_gold_version(3) # sliced, from latest version\n",
    "gold_2.to_pandas_dataframe().shape # (113, 11)"
   ]
  },
  {
   "source": [
    "# TRAIN - `AutoMLFactory + ComputeFactory`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baselayer_azure_ml import AutoMLFactory, ComputeFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "what environment are we targeting? =  test\n"
     ]
    }
   ],
   "source": [
    "p.dev_test_prod = \"test\"\n",
    "print(\"what environment are we targeting? =  {}\".format(p.dev_test_prod)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'enable_voting_ensemble': True,\n",
       " 'enable_stack_ensemble': True,\n",
       " 'model_explainability': True,\n",
       " 'experiment_timeout_hours': 24,\n",
       " 'iteration_timeout_minutes': 480,\n",
       " 'n_cross_validations': 9,\n",
       " 'enable_early_stopping': True,\n",
       " 'iterations': 1000,\n",
       " 'blocked_models': ['GradientBoosting',\n",
       "  'LightGBM',\n",
       "  'XGBoostRegressor',\n",
       "  'ExtremeRandomTrees',\n",
       "  'LassoLars',\n",
       "  'RandomForest',\n",
       "  'ElasticNet',\n",
       "  'AutoArima'],\n",
       " 'path': '.',\n",
       " 'debug_log': 'azure_automl_debug_test.log'}"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "automl_performance_config = p.get_automl_performance_config()\n",
    "automl_performance_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'enable_voting_ensemble': False,\n",
       " 'enable_stack_ensemble': False,\n",
       " 'model_explainability': False,\n",
       " 'experiment_timeout_hours': 0.25,\n",
       " 'iteration_timeout_minutes': 2,\n",
       " 'n_cross_validations': 2,\n",
       " 'enable_early_stopping': True,\n",
       " 'iterations': 100,\n",
       " 'allowed_models': ['LightGBM'],\n",
       " 'path': '.',\n",
       " 'debug_log': 'azure_automl_debug_dev.log'}"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "p.dev_test_prod = \"dev\"\n",
    "automl_performance_config = p.get_automl_performance_config()\n",
    "automl_performance_config"
   ]
  },
  {
   "source": [
    "# Get `COMPUTE` for current `ENVIRONMENT`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Note: USING enterprise performance settings. (This can be overridden in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=True\n",
      "Using a model specific cluster, per configuration in project specific settings, (the integer of 'model_number' is the base for the name)\n",
      "Note: USING enterprise performance settings. (This can be overridden in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=True\n",
      "Found existing cluster prj02-m03-dev for project and environment, using it.\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n"
     ]
    }
   ],
   "source": [
    "aml_compute = p.get_training_aml_compute(ws)"
   ]
  },
  {
   "source": [
    "# `TRAIN` model -> See other notebook `esml_howto_2_train.ipynb`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Experiment name: 03_diabetes_model_reg\n",
      "Azure ML Studio Workspace: msft-weu-DEV-eap-proj02_ai-amls\n",
      "Start training run...\n",
      "Submitting remote run.\n",
      "No run_configuration provided, running on prj02-m03-dev with default configuration\n",
      "Running on remote compute: prj02-m03-dev\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>03_diabetes_model_reg</td><td>AutoML_f8eaf762-9a0f-4834-98ae-ab1f5f42e542</td><td>automl</td><td>NotStarted</td><td><a href=\"https://ml.azure.com/runs/AutoML_f8eaf762-9a0f-4834-98ae-ab1f5f42e542?wsid=/subscriptions/ca0a8c40-b06a-4e4e-8434-63c03a1dee34/resourcegroups/MSFT-WEU-EAP_PROJECT02_AI-DEV-RG/workspaces/msft-weu-DEV-eap-proj02_ai-amls&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Current status: FeaturesGeneration. Generating features for the dataset.\n",
      "Something went wrong while printing the experiment progress but the run is still executing on the compute target. \n",
      "Please check portal for updated status: https://ml.azure.com/runs/AutoML_f8eaf762-9a0f-4834-98ae-ab1f5f42e542?wsid=/subscriptions/ca0a8c40-b06a-4e4e-8434-63c03a1dee34/resourcegroups/MSFT-WEU-EAP_PROJECT02_AI-DEV-RG/workspaces/msft-weu-DEV-eap-proj02_ai-amls&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AutoMLException",
     "evalue": "AutoMLException:\n\tMessage: Could not find a model with valid score for metric 'normalized_mean_absolute_error'. Please ensure that at least one run was successfully completed with a valid score for the given metric.\n\tInnerException: None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Could not find a model with valid score for metric 'normalized_mean_absolute_error'. Please ensure that at least one run was successfully completed with a valid score for the given metric.\",\n        \"target\": \"metric\",\n        \"inner_error\": {\n            \"code\": \"NotFound\",\n            \"inner_error\": {\n                \"code\": \"ModelMissing\"\n            }\n        }\n    }\n}",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAutoMLException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-1d26e9f5b83e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mvia_pipeline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mbest_run\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfitted_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexperiment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoMLFactory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mautoml_config\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mvia_pipeline\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mAutoMLFactory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_as_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mautoml_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\jostrm\\OneDrive - Microsoft\\0_GIT\\2_My\\github\\azure-enterprise-scale-ml\\esml\\common\\baselayer_azure_ml.py\u001b[0m in \u001b[0;36mtrain_as_run\u001b[1;34m(self, automl_config)\u001b[0m\n\u001b[0;32m    761\u001b[0m         \u001b[1;31m#automl_config.run_configuration  = aml_run_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 763\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mws\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mautoml_config\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdev_test_prod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    764\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mws\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mautoml_config\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdev_test_prod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jostrm\\OneDrive - Microsoft\\0_GIT\\2_My\\github\\azure-enterprise-scale-ml\\esml\\common\\baselayer_azure_ml.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, ws, automl_config, experiment_name, dev_test_prod)\u001b[0m\n\u001b[0;32m    772\u001b[0m         \u001b[0mremote_run\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mautoml_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m         \u001b[0mremote_run\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 774\u001b[1;33m         \u001b[0mbest_run\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfitted_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mremote_run\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    775\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_run\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfitted_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\azure_automl\\lib\\site-packages\\azureml\\train\\automl\\run.py\u001b[0m in \u001b[0;36mget_output\u001b[1;34m(self, iteration, metric, return_onnx_model, return_split_onnx_model, **kwargs)\u001b[0m\n\u001b[0;32m    708\u001b[0m                     \u001b[0monnx_compatible\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_onnx_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m                     \u001b[0msplit_onnx_model_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_split_onnx_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m                     \u001b[0mactivity_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mautoml_shared_constants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTelemetryConstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET_OUTPUT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m                 )\n\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\azure_automl\\lib\\site-packages\\azureml\\train\\automl\\run.py\u001b[0m in \u001b[0;36m_get_best_child_run\u001b[1;34m(self, iteration, metric, onnx_compatible, split_onnx_model_name, activity_name)\u001b[0m\n\u001b[0;32m    635\u001b[0m                     )\n\u001b[0;32m    636\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 637\u001b[1;33m                     \u001b[0mcurr_run\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_run_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"get_output\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    638\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mcurr_run\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m                         raise NotFoundException._with_error(\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\azure_automl\\lib\\site-packages\\azureml\\train\\automl\\run.py\u001b[0m in \u001b[0;36m_get_run_internal\u001b[1;34m(self, iteration, metric, operation_name)\u001b[0m\n\u001b[0;32m    795\u001b[0m                                                                 child_run_id=best_run_tag)\n\u001b[0;32m    796\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 797\u001b[1;33m                     \u001b[0mchild_runs_and_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_all_automl_child_runs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mautoml_settings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary_metric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    798\u001b[0m                     \u001b[0mcurr_run\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchild_runs_and_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\azure_automl\\lib\\site-packages\\azureml\\train\\automl\\run.py\u001b[0m in \u001b[0;36m_get_all_automl_child_runs\u001b[1;34m(self, metric)\u001b[0m\n\u001b[0;32m    836\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchild_runs_scores\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mAutoMLException\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_with_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAzureMLError\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModelMissing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"metric\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    839\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mchild_runs_scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAutoMLException\u001b[0m: AutoMLException:\n\tMessage: Could not find a model with valid score for metric 'normalized_mean_absolute_error'. Please ensure that at least one run was successfully completed with a valid score for the given metric.\n\tInnerException: None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Could not find a model with valid score for metric 'normalized_mean_absolute_error'. Please ensure that at least one run was successfully completed with a valid score for the given metric.\",\n        \"target\": \"metric\",\n        \"inner_error\": {\n            \"code\": \"NotFound\",\n            \"inner_error\": {\n                \"code\": \"ModelMissing\"\n            }\n        }\n    }\n}"
     ]
    }
   ],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "from baselayer_azure_ml import azure_metric_regression\n",
    "\n",
    "label = \"Y\"\n",
    "train_6, validate_set_2, test_set_2 = p.split_gold_3(0.6,label) # Auto-registerin AZURE (M03_GOLD_TRAIN | M03_GOLD_VALIDATE | M03_GOLD_TEST) # Alt: train,testv= p.Gold.random_split(percentage=0.8, seed=23)\n",
    "automl_config = AutoMLConfig(task = 'regression',\n",
    "                             primary_metric = azure_metric_regression.MAE,\n",
    "                             experiment_exit_score = '0.208', # DEMO purpose\n",
    "                             compute_target = aml_compute,\n",
    "                             training_data = p.GoldTrain, # is 'train_6' pandas dataframe, but as an Azure ML Dataset\n",
    "                             label_column_name = label,\n",
    "                             **automl_performance_config\n",
    "                            )\n",
    "\n",
    "via_pipeline = False\n",
    "best_run, fitted_model, experiment = AutoMLFactory(p).train_pipeline(automl_config) if via_pipeline else AutoMLFactory(p).train_as_run(automl_config)"
   ]
  },
  {
   "source": [
    "# END"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# ESML - accelerator\n",
    "\n",
    "## PROJECT + DATA CONCEPTS + ENTERPRISE Datalake Design + DEV->PROD MLOps\n",
    "- `1)ESML Project`: The ONLY thing you need to remember is your `Project number` (and `BRONZE, SILVER, GOLD` concept )\n",
    "    - ProjectNo=4 have a list of all your datasets as ESMLDatasets. (Well you need to provide names for them also: \"mydata01\", \"mydata02\" - but thats it)\n",
    "- `2)Lakedesign & Roles`: Bronze, silver, gold + IN and date folders\n",
    "    - Benefits: Physical datalake design!  onnected to Azure ML Workspace, with autoregistration of `Azure ML Datasets`\n",
    "    - `Role 1`: `Data ingestion team` only need to care about 1 thing - onboard data to `IN-folder`, in .CSV format\n",
    "        - `Auto parquet-conversion` from `IN` folder (.CSV) to `OUT`/BRONZE/bronze.PARQUET \n",
    "    - `Role 2`: `Data scientists` only need to care about 3 things (R/W): `BRONZE, SILVER, GOLD` datasets, all in .PARQUET format\n",
    "    - How? The ESML project will `Automap` and `Autoregister` Azure ML Datasets - `IN, SILVER, BRONZE, GOLD`\n",
    "- `2a) R&D  VS Production phase`: \"Latest data\" VS versioning on Datasets and datefolders  \n",
    "    - Benefits \"R&D mode\": Faster RnD phase to onboard and refresh data easy. Also fast \"flip-switch\" to production\n",
    "    - How? `ESMLDataset is context self aware` - knows when it is used in TRAIN or INFERENCE pipeline\n",
    "- `2b) TRAIN vs INFERENCE` versions</u> `Reuse (Bronze->Silver->Gold) pipepline`, for both TRAIN preprocessing, and INFERENCE \n",
    "    - Benefits: Inference with different MODEL version, on data from the same day/time, (to compare scoring etc)\n",
    "    - How? ESMLDataset have context self awareness, and `knows WHERE and HOW to load/save data`\n",
    "- `2c) BATCH CONFIG`: Turn on/off features on ALL datasets\n",
    "    - Accelerate setup: `Datadrift, Time series traits, Smart noise, etc`\n",
    "    - Share refined data back to its \"origin/non-projectbased structure\" easy: \n",
    "        - ESMLProject.ShareBack(ds.Silver)\n",
    "    - How? ESMProject controls all ESMDatasets, in a uniform way\n",
    "## ENTERPRISE Deployment of Models & Governance - MLOps  at scale\n",
    "- `3) DEV->TEST-PROD` (configs, compute, performance)\n",
    "    - ESML has config for 3 environemnts: Easy DEPLOY model across subscriptions and Azure ML Studio workspaces \n",
    "        - Save costs & time: \n",
    "            - `DEV` has cheaper compute performance for TRAIN and INFERENCE (batch, AKS)\n",
    "            - `DEV` has Quick-debug ML training (fast training...VS good scoring in TEST and PROD)\n",
    "        - How? ESML `AutoMLFactory` and `ComputeFactory`\n",
    "         \n",
    "\n",
    "### Q&A:\n",
    "- Q: Is ESML Machine learning specific? If I only want to refine some data...for integration, or report? \n",
    "- A: You can use this for just data refinement also: `Bronze->Silver->Gold` refinement.\n",
    "    - Benefits: Enterprise security, Read/write to datalake, easy to share refined data. \n",
    "    - Benefits: The tooling \"glued togehter\": Azure datafactory +  Azure Databricks (and Azure ML Studio pipelines if needed)\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}