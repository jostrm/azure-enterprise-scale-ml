{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3612jvsc74a57bd03fec2c5a411dce07235ef28c8752b6cecf1f94423de7e7c24e62fc38b1bc47de",
   "display_name": "Python 3.6.12 64-bit ('azure_automl': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 1) Init ESML "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training\n\n - ds01_diabetes\nmaster/1_projects/project002/03_diabetes_model_reg/train/ds01_diabetes/in/dev/2020/01/01/\nmaster/1_projects/project002/03_diabetes_model_reg/train/ds01_diabetes/out/bronze/dev/\nmaster/1_projects/project002/03_diabetes_model_reg/train/ds01_diabetes/out/silver/dev/\n\n - ds02_other\nmaster/1_projects/project002/03_diabetes_model_reg/train/ds02_other/in/dev/2020/01/01/\nmaster/1_projects/project002/03_diabetes_model_reg/train/ds02_other/out/bronze/dev/\nmaster/1_projects/project002/03_diabetes_model_reg/train/ds02_other/out/silver/dev/\nTraining GOLD \n\nmaster/1_projects/project002/03_diabetes_model_reg/train/gold/dev/\n \n\nENVIRONMENT - DEV, TEST, or PROD?\nACTIVE ENVIRONMENT = dev\nACTIVE subscription = ca0a8c40-b06a-4e4e-8434-63c03a1dee34\n- MSFT-WEU-EAP_PROJECT02_AI-DEV-RG\n- msft-weu-DEV-eap-proj02_ai-amls\n- westeurope\n- MSFT-WEU-EAP_CMN_AI-DEV-RG\n- msft-weu-dev-cmnai-vnet\n- msft-weu-dev-cmnai-sn-aml\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(os.path.abspath(\"../common/\"))  # NOQA: E402\n",
    "from esml import ESMLDataset, ESMLProject\n",
    "from azureml.core import Workspace\n",
    "\n",
    "p = ESMLProject() # Makes it \"environment aware (dev,test,prod)\", and \"configuration aware\"\n",
    "ws = p.get_workspace_from_config()\n",
    "p.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "unregister_all_datasets=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "...\n",
      "Using GEN2 as Datastore\n",
      "ds01_diabetes\n",
      "ds02_other\n",
      "\n",
      "####### Automap & Autoregister - SUCCESS!\n",
      "1) Auto mapped 2 ESML Dataset with registered Azure ML Datasets (potentially all 3: IN,BRONZE, SILVER) in Datastore project002lake \n",
      "\n",
      "Dataset 'ds01_diabetes' status:\n",
      " - IN_Folder_has_files\n",
      " - BRONZE_Folder_has_files\n",
      " - SILVER_Folder_has_files\n",
      "Dataset 'ds02_other' status:\n",
      " - IN_Folder_has_files\n",
      " - BRONZE_Folder_has_files\n",
      " - SILVER_Folder_has_files\n",
      "\n",
      "2) Registered each Dataset with suffixes (_IN_CSV, _BRONZE, _SILVER) \n",
      " Tip: Use ESMLProject.Datasets list or .DatasetByName(myDatasetName) to read/write\n",
      "#######\n"
     ]
    }
   ],
   "source": [
    "if(unregister_all_datasets):\n",
    "    p.unregister_all_datasets(ws) # For DEMO purpose\n",
    "\n",
    "p.init(ws) \n",
    "p.dev_test_prod = \"dev\"\n",
    "#Note: This happens in the INIT() method of DriverAPI/CallingAppliation...not loading for every Scoring"
   ]
  },
  {
   "source": [
    "# 2) Test an `existing` Model webservice (AKS)?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 2a) Lets simulate INFERENCE: data arives from CLIENT to a `DriverAPI` that itself will call `this ModelAPI` (AKS)\n",
    "Note: `Step 1 and 2 are out of scope` of from the MACHINE LEARNING solution (and ESML), other than...\n",
    " - `ESML` being the creator of AML pipeline - `Bronze_2_Gold` that you can reuse\n",
    " - `ESML lakedesign`, that should be used, if INFERENCE are to be stored/cached in the lake\n",
    "\n",
    "NOW - the scenario: \n",
    "\n",
    "- DriverAPI will:\n",
    "\n",
    "    - 1)Fetch missing datasources from different systems, to get all data sources ds01, ds02,ds03 & SAVE to INFERENCE/IN folder in the datalake\n",
    "        - Use the `ESML` lakedesign:  IF `inference_model_version=1` in `settings/project_specific/lake_settings.json` then...\n",
    "        - `ESML` will switch to write at `INFERENCE/v1/ds01/IN/2020/01/01` folder \n",
    "    - 2)Call `Bronze_2_Gold` batch pipeline (AML) - same pipeline that was used for training: `IN->Bronze->Silver->Gold`, except...\n",
    "        - `Bronze_2_Gold` pipeline will read from IN folder, but configured for \"INFERENCE\", read/write to `\"mirror\"` place in the datalake, that will `CACHE` online predicted results\n",
    "        - (LABEL values are missing of course)\n",
    "    - 3) `DriverAPI calls ModelAPI` (This AKS webservuce) with data to score -> `X_text`\n",
    "\n",
    "- `ESML` ModelAPI will:\n",
    "    - 4) `Score` the data, and return results, also `save the results to the datalake`\n",
    "        - if `p.rnd=True` nothing is stored.\n",
    "    - 5) `Connect the scored data` to a caller, and the individual scores to a identity (user/machine)\n",
    "        - GLOBALLY & ESML Managed: The scoring file gets a caller_id. \n",
    "            - You: Need to pass the called-guid as a parameter. \n",
    "                - Alternatively, you can have a column in the dataframe called `esml_caller_id_string`, and ESML will use that.\n",
    "        - LOCALLY: The rows in the dataframe has an identity. \n",
    "            - You: Here you need to have a column in the dataframe, such as `user_id`, to be able to connect each row to a scoring.\n",
    "\n",
    "\n",
    "Step 1 and 2 are out of scope of from the MACHINE LEARNING solution  \n",
    "We START this notebooke at step 3 - we have `X_test` in `GOLD_Validate` status "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021_04_10\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "now = dt.datetime.now()\n",
    "folder = now.strftime('%Y_%m_%d') \n",
    "print(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(unregister_all_datasets): # Create a GOLD dataset, and SPLIT it\n",
    "    df_01 = p.DatasetByName(\"ds01_diabetes\").Silver.to_pandas_dataframe()\n",
    "    ds_gold_v1 = p.save_gold(df_01)\n",
    "\n",
    "    label = \"Y\"\n",
    "    train_6, validate_set_2, test_set_2 = p.split_gold_3(0.6, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "M03_GOLD_VALIDATE : (37, 11)\nX_test  (37, 10)\ny_test  (37,)\n{'split_percentage': '0.2', 'label': 'Y'}\n"
     ]
    }
   ],
   "source": [
    "# 2) Bronze_2_Gold done, we can fetch X_test\n",
    "X_test, y_test, tags = p.get_gold_validate_Xy() # Version is default latest\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        AGE       SEX       BMI        BP        S1        S2        S3  \\\n",
       "0  0.048974  0.050680  0.123131  0.083844 -0.104765 -0.100895 -0.069172   \n",
       "1  0.070769 -0.044642  0.069241  0.037939  0.021822  0.001504 -0.036038   \n",
       "2  0.056239  0.050680 -0.030996  0.008101  0.019070  0.021233  0.033914   \n",
       "3  0.016281 -0.044642  0.017506 -0.022885  0.060349  0.044406  0.030232   \n",
       "4  0.023546 -0.044642  0.110198  0.063187  0.013567 -0.032942 -0.024993   \n",
       "\n",
       "         S4        S5        S6  \n",
       "0 -0.002592  0.036646 -0.030072  \n",
       "1  0.039106  0.077633  0.106617  \n",
       "2 -0.039493 -0.029528 -0.059067  \n",
       "3 -0.002592  0.037232 -0.001078  \n",
       "4  0.020655  0.099240  0.023775  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AGE</th>\n      <th>SEX</th>\n      <th>BMI</th>\n      <th>BP</th>\n      <th>S1</th>\n      <th>S2</th>\n      <th>S3</th>\n      <th>S4</th>\n      <th>S5</th>\n      <th>S6</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.048974</td>\n      <td>0.050680</td>\n      <td>0.123131</td>\n      <td>0.083844</td>\n      <td>-0.104765</td>\n      <td>-0.100895</td>\n      <td>-0.069172</td>\n      <td>-0.002592</td>\n      <td>0.036646</td>\n      <td>-0.030072</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.070769</td>\n      <td>-0.044642</td>\n      <td>0.069241</td>\n      <td>0.037939</td>\n      <td>0.021822</td>\n      <td>0.001504</td>\n      <td>-0.036038</td>\n      <td>0.039106</td>\n      <td>0.077633</td>\n      <td>0.106617</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.056239</td>\n      <td>0.050680</td>\n      <td>-0.030996</td>\n      <td>0.008101</td>\n      <td>0.019070</td>\n      <td>0.021233</td>\n      <td>0.033914</td>\n      <td>-0.039493</td>\n      <td>-0.029528</td>\n      <td>-0.059067</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.016281</td>\n      <td>-0.044642</td>\n      <td>0.017506</td>\n      <td>-0.022885</td>\n      <td>0.060349</td>\n      <td>0.044406</td>\n      <td>0.030232</td>\n      <td>-0.002592</td>\n      <td>0.037232</td>\n      <td>-0.001078</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.023546</td>\n      <td>-0.044642</td>\n      <td>0.110198</td>\n      <td>0.063187</td>\n      <td>0.013567</td>\n      <td>-0.032942</td>\n      <td>-0.024993</td>\n      <td>0.020655</td>\n      <td>0.099240</td>\n      <td>0.023775</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "source": [
    "### 2b) Call onlin ModelAPI - score 1 row (alt 1)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "import pandas as pd\n",
    "#3) `DriverAPI calls ModelAPI`\n",
    "\n",
    "keyvault = p.ws.get_default_keyvault()\n",
    "api_url = keyvault.get_secret(name=\"esml-dev-p02-m03-api\")\n",
    "api_key = keyvault.get_secret(name=\"esml-dev-p02-m03-apisecret\")  # esml-dev-p02-m03-apisecret\n",
    "\n",
    "df = ESMLProject.call_webservice_own_url(X_test, api_url,api_key) # rest call. STATIC method - simulate \"we dont need ESML for this\" - just an URL and KEY from DriverAPI\n",
    "df.head() # Print scoring"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 2b) Call online ModelAPI - score all rows (alt 2) - `via ESML wrapper`\n",
    "- ESML benefits: Has built in `logic` to save scored_results, to unique folders during the day.\n",
    "- Note: We can also save a GUID/ID, `to see which CALLER/User-Guid the scoring is about` \n",
    "    - We can have a User_id_GUID as a \"feature/column\" in X_test, or as a parameter in the call"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "master/1_projects/project002/03_diabetes_model_reg/inference/1/scored/dev/\n"
     ]
    }
   ],
   "source": [
    "p.inferenceModelVersion=1\n",
    "print(p.ScoredPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Note: USING enterprise performance settings. (This can be overridden in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=True\n",
      "Note: Fetching keys automatically via workspace keyvault.\n",
      "Saving scoring to lake for project folder project002 and inference_model_version: 1 ...\n",
      "...\n",
      "..\n",
      "\n",
      "Saved DATA to score successfully in LAKE, as file 'to_score_81965d9c-40ca-4e47-9723-5a608a32a0e4.parquet'\n",
      "..\n",
      "Saved SCORED data in LAKE, as file 'scored_81965d9c-40ca-4e47-9723-5a608a32a0e4.parquet'\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        AGE       SEX       BMI        BP        S1        S2        S3  \\\n",
       "0  0.048974  0.050680  0.123131  0.083844 -0.104765 -0.100895 -0.069172   \n",
       "1  0.070769 -0.044642  0.069241  0.037939  0.021822  0.001504 -0.036038   \n",
       "2  0.056239  0.050680 -0.030996  0.008101  0.019070  0.021233  0.033914   \n",
       "3  0.016281 -0.044642  0.017506 -0.022885  0.060349  0.044406  0.030232   \n",
       "4  0.023546 -0.044642  0.110198  0.063187  0.013567 -0.032942 -0.024993   \n",
       "\n",
       "         S4        S5        S6      result  \n",
       "0 -0.002592  0.036646 -0.030072  243.130371  \n",
       "1  0.039106  0.077633  0.106617  293.235993  \n",
       "2 -0.039493 -0.029528 -0.059067   94.014447  \n",
       "3 -0.002592  0.037232 -0.001078  148.809757  \n",
       "4  0.020655  0.099240  0.023775  252.999922  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AGE</th>\n      <th>SEX</th>\n      <th>BMI</th>\n      <th>BP</th>\n      <th>S1</th>\n      <th>S2</th>\n      <th>S3</th>\n      <th>S4</th>\n      <th>S5</th>\n      <th>S6</th>\n      <th>result</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.048974</td>\n      <td>0.050680</td>\n      <td>0.123131</td>\n      <td>0.083844</td>\n      <td>-0.104765</td>\n      <td>-0.100895</td>\n      <td>-0.069172</td>\n      <td>-0.002592</td>\n      <td>0.036646</td>\n      <td>-0.030072</td>\n      <td>243.130371</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.070769</td>\n      <td>-0.044642</td>\n      <td>0.069241</td>\n      <td>0.037939</td>\n      <td>0.021822</td>\n      <td>0.001504</td>\n      <td>-0.036038</td>\n      <td>0.039106</td>\n      <td>0.077633</td>\n      <td>0.106617</td>\n      <td>293.235993</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.056239</td>\n      <td>0.050680</td>\n      <td>-0.030996</td>\n      <td>0.008101</td>\n      <td>0.019070</td>\n      <td>0.021233</td>\n      <td>0.033914</td>\n      <td>-0.039493</td>\n      <td>-0.029528</td>\n      <td>-0.059067</td>\n      <td>94.014447</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.016281</td>\n      <td>-0.044642</td>\n      <td>0.017506</td>\n      <td>-0.022885</td>\n      <td>0.060349</td>\n      <td>0.044406</td>\n      <td>0.030232</td>\n      <td>-0.002592</td>\n      <td>0.037232</td>\n      <td>-0.001078</td>\n      <td>148.809757</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.023546</td>\n      <td>-0.044642</td>\n      <td>0.110198</td>\n      <td>0.063187</td>\n      <td>0.013567</td>\n      <td>-0.032942</td>\n      <td>-0.024993</td>\n      <td>0.020655</td>\n      <td>0.099240</td>\n      <td>0.023775</td>\n      <td>252.999922</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "caller_user_id = '81965d9c-40ca-4e47-9723-5a608a32a0e4' # Connect the scoring to a caller/user, globally for all rows\n",
    "\n",
    "df = p.call_webservice(p.ws, X_test, caller_user_id, False) # Auto-fetch key from keyvault, 1stRowOnlye=False\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "# 3) How to GET SCORE data? how to FILTER scored results?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "M03_GOLD_VALIDATE : (37, 11)\n",
      "X_test  (37, 10)\n",
      "y_test  (37,)\n",
      "Note: USING enterprise performance settings. (This can be overridden in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=True\n",
      "Note: Fetching keys automatically via workspace keyvault.\n",
      "Saving scoring to lake for project folder project002 and inference_model_version: 1 ...\n",
      "...\n",
      "\n",
      "Saved DATA to score successfully in LAKE, as file 'to_score_91965d9c-40ca-4e47-9723-5a608a32a0e4.parquet'\n",
      "Saved SCORED data in LAKE, as file 'scored_91965d9c-40ca-4e47-9723-5a608a32a0e4.parquet'\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        AGE       SEX       BMI        BP        S1        S2        S3  \\\n",
       "0  0.048974  0.050680  0.123131  0.083844 -0.104765 -0.100895 -0.069172   \n",
       "1  0.070769 -0.044642  0.069241  0.037939  0.021822  0.001504 -0.036038   \n",
       "2  0.056239  0.050680 -0.030996  0.008101  0.019070  0.021233  0.033914   \n",
       "3  0.016281 -0.044642  0.017506 -0.022885  0.060349  0.044406  0.030232   \n",
       "4  0.023546 -0.044642  0.110198  0.063187  0.013567 -0.032942 -0.024993   \n",
       "\n",
       "         S4        S5        S6      result  \n",
       "0 -0.002592  0.036646 -0.030072  243.130371  \n",
       "1  0.039106  0.077633  0.106617  293.235993  \n",
       "2 -0.039493 -0.029528 -0.059067   94.014447  \n",
       "3 -0.002592  0.037232 -0.001078  148.809757  \n",
       "4  0.020655  0.099240  0.023775  252.999922  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AGE</th>\n      <th>SEX</th>\n      <th>BMI</th>\n      <th>BP</th>\n      <th>S1</th>\n      <th>S2</th>\n      <th>S3</th>\n      <th>S4</th>\n      <th>S5</th>\n      <th>S6</th>\n      <th>result</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.048974</td>\n      <td>0.050680</td>\n      <td>0.123131</td>\n      <td>0.083844</td>\n      <td>-0.104765</td>\n      <td>-0.100895</td>\n      <td>-0.069172</td>\n      <td>-0.002592</td>\n      <td>0.036646</td>\n      <td>-0.030072</td>\n      <td>243.130371</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.070769</td>\n      <td>-0.044642</td>\n      <td>0.069241</td>\n      <td>0.037939</td>\n      <td>0.021822</td>\n      <td>0.001504</td>\n      <td>-0.036038</td>\n      <td>0.039106</td>\n      <td>0.077633</td>\n      <td>0.106617</td>\n      <td>293.235993</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.056239</td>\n      <td>0.050680</td>\n      <td>-0.030996</td>\n      <td>0.008101</td>\n      <td>0.019070</td>\n      <td>0.021233</td>\n      <td>0.033914</td>\n      <td>-0.039493</td>\n      <td>-0.029528</td>\n      <td>-0.059067</td>\n      <td>94.014447</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.016281</td>\n      <td>-0.044642</td>\n      <td>0.017506</td>\n      <td>-0.022885</td>\n      <td>0.060349</td>\n      <td>0.044406</td>\n      <td>0.030232</td>\n      <td>-0.002592</td>\n      <td>0.037232</td>\n      <td>-0.001078</td>\n      <td>148.809757</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.023546</td>\n      <td>-0.044642</td>\n      <td>0.110198</td>\n      <td>0.063187</td>\n      <td>0.013567</td>\n      <td>-0.032942</td>\n      <td>-0.024993</td>\n      <td>0.020655</td>\n      <td>0.099240</td>\n      <td>0.023775</td>\n      <td>252.999922</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "X_test, y_test, tags = p.get_gold_validate_Xy()\n",
    "caller_user_id = '91965d9c-40ca-4e47-9723-5a608a32a0e4' # Connect the scoring to a caller/user, globally for all rows\n",
    "\n",
    "df = p.call_webservice(p.ws, X_test, caller_user_id, False) # Auto-fetch key from keyvault, 1stRowOnlye=False\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021_04_10\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "now = dt.datetime.now()\n",
    "date_filter = now.strftime('%Y_%m_%d') \n",
    "print(date_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_list, df_all = p.get_scored(date_filter, \"10\",'81965d9c-40ca-4e47-9723-5a608a32a0e4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Datasets found in filter 1\n",
      "Example: How many rows in 1st dataset?  37\n",
      "All rows 37\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        AGE       SEX       BMI        BP        S1        S2        S3  \\\n",
       "0  0.048974  0.050680  0.123131  0.083844 -0.104765 -0.100895 -0.069172   \n",
       "1  0.070769 -0.044642  0.069241  0.037939  0.021822  0.001504 -0.036038   \n",
       "2  0.056239  0.050680 -0.030996  0.008101  0.019070  0.021233  0.033914   \n",
       "3  0.016281 -0.044642  0.017506 -0.022885  0.060349  0.044406  0.030232   \n",
       "4  0.023546 -0.044642  0.110198  0.063187  0.013567 -0.032942 -0.024993   \n",
       "\n",
       "         S4        S5        S6      result  \n",
       "0 -0.002592  0.036646 -0.030072  243.130371  \n",
       "1  0.039106  0.077633  0.106617  293.235993  \n",
       "2 -0.039493 -0.029528 -0.059067   94.014447  \n",
       "3 -0.002592  0.037232 -0.001078  148.809757  \n",
       "4  0.020655  0.099240  0.023775  252.999922  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AGE</th>\n      <th>SEX</th>\n      <th>BMI</th>\n      <th>BP</th>\n      <th>S1</th>\n      <th>S2</th>\n      <th>S3</th>\n      <th>S4</th>\n      <th>S5</th>\n      <th>S6</th>\n      <th>result</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.048974</td>\n      <td>0.050680</td>\n      <td>0.123131</td>\n      <td>0.083844</td>\n      <td>-0.104765</td>\n      <td>-0.100895</td>\n      <td>-0.069172</td>\n      <td>-0.002592</td>\n      <td>0.036646</td>\n      <td>-0.030072</td>\n      <td>243.130371</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.070769</td>\n      <td>-0.044642</td>\n      <td>0.069241</td>\n      <td>0.037939</td>\n      <td>0.021822</td>\n      <td>0.001504</td>\n      <td>-0.036038</td>\n      <td>0.039106</td>\n      <td>0.077633</td>\n      <td>0.106617</td>\n      <td>293.235993</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.056239</td>\n      <td>0.050680</td>\n      <td>-0.030996</td>\n      <td>0.008101</td>\n      <td>0.019070</td>\n      <td>0.021233</td>\n      <td>0.033914</td>\n      <td>-0.039493</td>\n      <td>-0.029528</td>\n      <td>-0.059067</td>\n      <td>94.014447</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.016281</td>\n      <td>-0.044642</td>\n      <td>0.017506</td>\n      <td>-0.022885</td>\n      <td>0.060349</td>\n      <td>0.044406</td>\n      <td>0.030232</td>\n      <td>-0.002592</td>\n      <td>0.037232</td>\n      <td>-0.001078</td>\n      <td>148.809757</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.023546</td>\n      <td>-0.044642</td>\n      <td>0.110198</td>\n      <td>0.063187</td>\n      <td>0.013567</td>\n      <td>-0.032942</td>\n      <td>-0.024993</td>\n      <td>0.020655</td>\n      <td>0.099240</td>\n      <td>0.023775</td>\n      <td>252.999922</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "#df = p.get_scored('last_month')\n",
    "ds_list1, df_all1 = p.get_scored(date_filter, \"1\",'81965d9c-40ca-4e47-9723-5a608a32a0e4')\n",
    "print(\"Datasets found in filter\", len(ds_list1))\n",
    "print(\"Example: How many rows in 1st dataset? \", ds_list1[0].to_pandas_dataframe().shape[0])\n",
    "print(\"All rows\", df_all1.shape[0])\n",
    "\n",
    "df_all1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Datasets found in filter 2\n",
      "Example: How many rows in 1st dataset?  37\n",
      "All rows 74\n"
     ]
    }
   ],
   "source": [
    "ds_list, df_all = p.get_scored(date_filter, \"1\")\n",
    "print(\"Datasets found in filter\", len(ds_list))\n",
    "print(\"Example: How many rows in 1st dataset? \", ds_list[0].to_pandas_dataframe().shape[0])\n",
    "print(\"All rows\", df_all.shape[0])"
   ]
  },
  {
   "source": [
    " ** Train model & register ....this happended already in another notebook/MLops pipline step\n",
    "> model = p.register_active_model()  \n",
    "> print(model.name, model.description, model.version)  \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 3a) ESML `Deploy a new ONLINE` webservice (AKS)\n",
    "- Deploy \"offline\" from old `AutoML run` for `DEV` environment\n",
    "- To →  `DEV`, `TEST` or `PROD` environment\n",
    "- ESML saves `API_key in Azure keyvault automatically`\n",
    "- ESML auto-config solves 4 common 'errors/things': `correct compute name` and `valid replicas, valid agents, valid auto scaling`\n",
    "    - Tip: You can adjust the number of replicas, and different CPU/memory configuration, or using a different compute target."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_config, model, best_run = p.get_active_model_inference_config(ws) #  AutoML support \n",
    "service,api_uri, kv_aks_api_secret= p.deploy_automl_model_to_aks(model,inference_config, True) # overwrite_endpoint=True"
   ]
  },
  {
   "source": [
    "# Test the NEW AKS WebService"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test, tags = p.get_gold_validate_Xy() # Version is default latest\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = p.call_webservice(p.ws, X_test) # Auto-fetch key from keyvault, 1stRowOnlye=False  |   p.call_webservice(p.ws, X_test, caller_user_id, False)\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "# Code to `embed in YOUR DriverApi` - to call this webservice `without ESML`\n",
    "- `NB!` This will `NOT cache` the results automatically, since not going via the ESML SDK. You need to save the scoring yourself ( if this is needed)\n",
    "    - ESML benefits: Has built in `logic` to save scored_results, to unique folders during the day.\n",
    "            # Note: We can also save a GUID/ID, for which CALLER/User-Guid it is about. We can have a User_id_GUID as a \"feature/column\" in X_test, or as a parameter"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_webservice_code(rows, api_uri,api_key, allowSelfSigned=True):\n",
    "    # bypass the server certificate verification on client side\n",
    "    if allowSelfSigned and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "    X_test_json_works = json.dumps({'data': rows.to_dict(orient='records')})\n",
    "\n",
    "    headers = {'Content-Type':'application/json', 'Authorization': 'Bearer ' + api_key}\n",
    "    resp = requests.post(api_uri, X_test_json_works , headers=headers) \n",
    "\n",
    "    # Here you can pass forward the response, save it to the datalake, or as below return a PANDAS dataframe\n",
    "    res_dict = json.loads(resp.text)\n",
    "    res_dict_ast = ast.literal_eval(res_dict)\n",
    "    return pd.read_json(res_dict) # to pandas"
   ]
  },
  {
   "source": [
    "## 3b) ESML `Deploy BATCH` pipeline\n",
    "- Deploy same model \"offline / previous\" `AutoML Run` for `DEV` environment\n",
    "- To →  `DEV`, `TEST` or `PROD` environment\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 5a alt2) If not using AutoML - you need to manuallt create `environemnt + entryscript + inference config`\n",
    "https://github.com/Azure/MachineLearningNotebooks/blob/bda592a236eaf2dbc54b394e1fa1b539e0297908/how-to-use-azureml/deployment/production-deploy-to-aks/production-deploy-to-aks.ipynb"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ENVIRONMENT - If not AUTOML\n",
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "conda_deps = CondaDependencies.create(conda_packages=['numpy','scikit-learn==0.19.1','scipy'], pip_packages=['azureml-defaults', 'inference-schema'])\n",
    "myenv = Environment(name='myenv')\n",
    "myenv.python.conda_dependencies = conda_deps"
   ]
  },
  {
   "source": [
    "%%writefile score.py\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import numpy\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    # AZUREML_MODEL_DIR is an environment variable created during deployment.\n",
    "    # It is the path to the model folder (./azureml-models/$MODEL_NAME/$VERSION)\n",
    "    # For multiple models, it points to the folder containing all deployed models (./azureml-models)\n",
    "    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'sklearn_regression_model.pkl')\n",
    "    # deserialize the model file back into a sklearn model\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# note you can pass in multiple rows for scoring\n",
    "def run(raw_data):\n",
    "    try:\n",
    "        data = json.loads(raw_data)['data']\n",
    "        data = numpy.array(data)\n",
    "        result = model.predict(data)\n",
    "        # you can return any data type as long as it is JSON-serializable\n",
    "        return result.tolist()\n",
    "    except Exception as e:\n",
    "        error = str(e)\n",
    "        return error"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.model import InferenceConfig\n",
    "inf_config = InferenceConfig(entry_script='score.py', environment=myenv)"
   ]
  },
  {
   "source": [
    "# OTHER - What more can you retrieve from AutoMLFactory and ESMLProject?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baselayer_azure_ml import AutoMLFactory\n",
    "from baselayer_azure_ml import ComputeFactory\n",
    "\n",
    "target_model, target_best_run_id = AutoMLFactory().get_latest_model(ws)\n",
    "print(target_model.name)\n",
    "print(target_best_run_id)\n",
    "\n",
    "run, exp = p.get_active_model_run_and_experiment()\n",
    "inference_config = p.get_active_model_inference_config()\n",
    "print(run)\n",
    "print(exp.name)"
   ]
  }
 ]
}