{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Always run thic CELL below\n",
    "- To attach ESML controlplane to your project\n",
    "- To point at `template-data` for the pipelinbe to know the schema of data\n",
    "- To init the ESMLPieplinefactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lake_settings.json with ESML version 1.4 - Models array support including LABEL\n",
      "\n",
      " ---- Q: WHICH files are generated as templates, for you to EDIT? ---- \n",
      "A: These files & locations:\n",
      "File to EDIT (step: IN_2_SILVER_1): ../../../2_A_aml_pipeline/4_inference/batch/M11/in2silver_ds01_diabetes.py\n",
      "File to EDIT (step: IN_2_SILVER_2): ../../../2_A_aml_pipeline/4_inference/batch/M11/in2silver_ds02_other.py\n",
      "File to EDIT (step: SILVER_MERGED_2_GOLD): ../../../2_A_aml_pipeline/4_inference/batch/M11/silver_merged_2_gold.py\n",
      "File to EDIT (step: SCORING_GOLD): ../../../2_A_aml_pipeline/4_inference/batch/M11/scoring_gold.py\n",
      "File to EDIT (step: TRAIN_SPLIT_AND_REGISTER): ../../../2_A_aml_pipeline/4_inference/batch/M11/train_split_and_register.py\n",
      "File to EDIT (step: TRAIN_MANUAL): ../../../2_A_aml_pipeline/4_inference/batch/M11/train_manual.py\n",
      "File to EDIT a lot (reference in step-scripts Custom code): ../../../2_A_aml_pipeline/4_inference/batch/M11/your_code/your_custom_code.py\n",
      "\n",
      " ---- WHAT model to SCORE with, & WHAT data 'date_folder'? ---- \n",
      "InferenceModelVersion (model version to score with): 1\n",
      "Date_scoring_folder (data to score) : 1000-01-01 10:35:01.243860\n",
      "ESML environment: dev\n",
      "Inference mode (self.batch_pipeline_parameters[4]): 0\n",
      "\n",
      " ---- ESML Datalake locations: ESML Datasets (IN-data) ---- \n",
      "Name (lake folder): ds01_diabetes and AzureName IN: M11_ds01_diabetes_train_IN\n",
      "IN projects/project002/11_diabetes_model_reg/train/ds01_diabetes/in/dev/1000/01/01/\n",
      "Bronze projects/project002/11_diabetes_model_reg/train/ds01_diabetes/out/bronze/dev/\n",
      "Silver projects/project002/11_diabetes_model_reg/train/ds01_diabetes/out/silver/dev/\n",
      "\n",
      "Name (lake folder): ds02_other and AzureName IN: M11_ds02_other_train_IN\n",
      "IN projects/project002/11_diabetes_model_reg/train/ds02_other/in/dev/1000/01/01/\n",
      "Bronze projects/project002/11_diabetes_model_reg/train/ds02_other/out/bronze/dev/\n",
      "Silver projects/project002/11_diabetes_model_reg/train/ds02_other/out/silver/dev/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../azure-enterprise-scale-ml/esml/common/\")\n",
    "from esml import ESMLProject\n",
    "from baselayer_azure_ml_pipeline import ESMLPipelineFactory, esml_pipeline_types\n",
    "\n",
    "p = ESMLProject()\n",
    "p.inference_mode = False\n",
    "p.active_model = 11 # 10=titanic , 11=Diabetes\n",
    "p_factory = ESMLPipelineFactory(p)\n",
    "\n",
    "scoring_date = '1000-01-01 10:35:01.243860' # \n",
    "p_factory.batch_pipeline_parameters[1].default_value = scoring_date # overrides ESMLProject.date_scoring_folder.\n",
    "p_factory.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IN_2_GOLD_TRAIN_MANUAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override default CURATED environment = \"AzureML-AutoML-DNN\", \"AzureML-lightgbm-3.2-ubuntu18.04-py37-cpu\"\n",
    "p_factory.use_curated_automl_environment = True\n",
    "p_factory.environment_name = \"AzureML-AutoML\" # Training[ \"AzureML-AutoML\", \"AzureML-lightgbm-3.2-ubuntu18.04-py37-cpu\"]  Inference[\"AzureML-sklearn-0.24.1-ubuntu18.04-py37-cpu-inference\",\"AzureML-lightgbm-3.2-ubuntu18.04-py37-cpu\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did NOT overwrite script-files with template-files such as 'scoring_gold.py', since overwrite_if_exists=False\n",
      "Using GEN2 as Datastore\n",
      "ESML will auto-create a compute...\n",
      "Note: OVERRIDING enterprise performance settings with project specifics. (to change, set flag in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=False)\n",
      "Using a model specific cluster, per configuration in project specific settings, (the integer of 'model_number' is the base for the name)\n",
      "Note: OVERRIDING enterprise performance settings with project specifics. (to change, set flag in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=False)\n",
      "Found existing cluster p02-m11weu-dev for project and environment, using it.\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n",
      "image_build_compute = p02-m11weu-dev\n",
      "Reusing existing compute...\n",
      "create_gold_train_step: inference_mode=False\n",
      "ESML-train_path_out = \n",
      "Tryingt to get CURRENT leader model from Azure ML Studio workspace - remotely.This might be the first time training model. then None is returned \n",
      "\n",
      "It was not an AutoMLRun() Lets init it as a regular Run()\n",
      "train_folder_template_with_date_id: projects/project002/11_diabetes_model_reg/train/gold/dev/{id_folder}/\n"
     ]
    }
   ],
   "source": [
    "## BUILD\n",
    "p_factory.create_dataset_scripts_from_template(overwrite_if_exists=False) # Do this once, then edit them manually. overwrite_if_exists=False is DEFAULT\n",
    "batch_pipeline = p_factory.create_batch_pipeline(esml_pipeline_types.IN_2_GOLD_TRAIN_MANUAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execute_pipeline (scoring): Inference_mode: 0\n",
      "-Scoring data, default value 1000-01-01 10:35:01.243860\n",
      "Created step IN 2 SILVER - ds01_diabetes [3ed2c01c][f8e9dbdd-f7bb-405d-bb47-5814910aaaf1], (This step will run and generate new outputs)Created step IN 2 SILVER - ds02_other [112ebeb6][c6a7156d-6f83-4a94-92b7-8c438be95138], (This step will run and generate new outputs)\n",
      "\n",
      "Created step SILVER MERGED 2 GOLD [a6e68140][d441ae09-147a-42e2-b0c1-8ab184253527], (This step will run and generate new outputs)\n",
      "Created step SPLIT AND REGISTER datasets [e455000b][c2d27648-b468-4bbb-bce7-de3909e41dbb], (This step will run and generate new outputs)\n",
      "Created step TRAIN in  [dev], COMPARE & REGISTER model in [dev] & PROMOTE to [test] [4271abea][ba2efead-345a-47e4-8a2d-7aee0801f0f0], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 7fdb8c97-66d8-4f5a-9d5b-4509d3b4adc2\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/7fdb8c97-66d8-4f5a-9d5b-4509d3b4adc2?wsid=/subscriptions/ca0a8c40-b06a-4e4e-8434-63c03a1dee34/resourcegroups/MSFT-WEU-EAP_PROJECT02_AI-DEV-RG/workspaces/msft-weu-DEV-eap-proj02_ai-amls&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "Pipeline submitted for execution!\n",
      " ### \n",
      "PipelineRunId: 7fdb8c97-66d8-4f5a-9d5b-4509d3b4adc2\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/7fdb8c97-66d8-4f5a-9d5b-4509d3b4adc2?wsid=/subscriptions/ca0a8c40-b06a-4e4e-8434-63c03a1dee34/resourcegroups/MSFT-WEU-EAP_PROJECT02_AI-DEV-RG/workspaces/msft-weu-DEV-eap-proj02_ai-amls&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## RUN\n",
    "pipeline_run = p_factory.execute_pipeline(batch_pipeline)\n",
    "pipeline_run.wait_for_completion(show_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pub_pipe.name 11_diabetes_model_reg_pipe_IN_2_GOLD_SCORING_EP_6\n",
      "pub_pipe.id 01274209-95e8-4ffb-9b95-9bfb1c865b28\n",
      "pub_pipe.name 11_diabetes_model_reg_pipe_IN_2_GOLD_SCORING_EP_1\n",
      "pub_pipe.id cb6e1ef3-ddf2-483c-964e-bc6ba02c610f\n",
      "pub_pipe.name 10_titanic_model_clas_pipe_IN_2_GOLD_SCORING_EP_1\n",
      "pub_pipe.id 6c3c51e9-df26-4373-ae37-0a31a3616ec0\n"
     ]
    }
   ],
   "source": [
    "# PUBLISH\n",
    "published_pipeline, endpoint = p_factory.publish_pipeline(batch_pipeline,\"_1\") # \"_1\" is optional    to create a NEW pipeline with 0 history, not ADD version to existing pipe & endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get info - to use  in Azure data factory: `published_pipeline.id` (if private Azure ML workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2) Fetch scored data: Below needed for Azure Data factory PIPELINE activity (Pipeline OR Endpoint. Choose the latter\n",
      "- Endpoint ID\n",
      "Endpoint ID:  6c3c51e9-df26-4373-ae37-0a31a3616ec0\n",
      "Endpoint Name:  10_titanic_model_clas_pipe_IN_2_GOLD_SCORING_EP_1\n",
      "Experiment name:  10_titanic_model_clas_pipe_IN_2_GOLD_SCORING\n",
      "In AZURE DATA FACTORY - This is the ID you need, if using PRIVATE LINK, private Azure ML workspace.\n",
      "-You need PIPELINE id, not pipeline ENDPOINT ID ( since cannot be chosen in Azure data factory if private Azure ML)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0a3ffd65-f1e2-4705-8fd0-681e4d16fbe4'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"2) Fetch scored data: Below needed for Azure Data factory PIPELINE activity (Pipeline OR Endpoint. Choose the latter\") \n",
    "print (\"- Endpoint ID\")\n",
    "print(\"Endpoint ID:  {}\".format(endpoint.id))\n",
    "print(\"Endpoint Name:  {}\".format(endpoint.name))\n",
    "print(\"Experiment name:  {}\".format(p_factory.experiment_name))\n",
    "\n",
    "print(\"In AZURE DATA FACTORY - This is the ID you need, if using PRIVATE LINK, private Azure ML workspace.\")\n",
    "print(\"-You need PIPELINE id, not pipeline ENDPOINT ID ( since cannot be chosen in Azure data factory if private Azure ML)\")\n",
    "published_pipeline.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('azure_automl_esml_v144')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a4a3f6f829c0fbf992fdd78de6ec4e694e293d154a9b96895f90a426de0ee97e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
