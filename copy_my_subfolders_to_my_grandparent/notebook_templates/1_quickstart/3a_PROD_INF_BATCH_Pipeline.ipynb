{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRODUCTION phase: About this notebook\n",
    "- Purpose: Creates 1 PIPELINE to serve the model.\n",
    "    - `Batch scoring pipeline:` Fetches the best trained model, BUILDs an `Azure Machine Learning pipeline`, to batch score the data in a scheduled or triggered way\n",
    "\n",
    "## DETAILS - about this notebook and the 2 pipelines, generated            \n",
    "- 1) Initiate ESMLPipelineFactory:\n",
    "- 2) `AUTO-GENERATE code: a snapshot folder` via ESML, that generates Python scripts and the `ESML runtime`\n",
    "    - azure-enterprise-scale-ml\\2_A_aml_pipeline\\4_inference\\batch\\\\`M11`\n",
    "        - Edit the feature engineering files if needed\n",
    "            - azure-enterprise-scale-ml\\2_A_aml_pipeline\\4_inference\\batch\\\\`M11\\your_code\\your_custom_code.py`\n",
    "            - `your_custom_code.py` is referenced from all the `in_2_silver_...` files, such as: 2_A_aml_pipeline\\4_inference\\batch\\M11\\\\`in2silver_ds01_diabetes.py`  and `silver_merged_2_gold`\n",
    "- 3) `BUILDS the pipeline` of certain type IN_2_GOLD_SCORING\n",
    "    - `An Azure Machine Learning pipeline` with steps will be auto-generated by ESML, based on your `lake_settings.json` dataset array.\n",
    "    - 3b) BUILDS a `training pipeline` of ESML type `IN_2_GOLD_SCORING`\n",
    "- 4) `EXECUTES the pipeline` (smoke testing purpose - see that it works...)\n",
    "    - 4b) Batch scoring pipeline (`IN_2_GOLD_SCORING`)\n",
    "        - Feature engineering of each in-data - via `IN_2_SILVER` step (here sample data is needed, or else StreamAccessException)\n",
    "        - Merges all SILVERS to `GOLD`\n",
    "        - Score data: Fetched the best trained model, leading model, to score with\n",
    "        - Saves scored data to the datalake, and writes metadata about WHAT data was scored, WHEN was the scoring, and with WHAT model_version was used.\n",
    "- 5) PUBLISH the pipeline\n",
    "    - Purpose: Now when the pipeline is `smoke tested`, we can publish is, to get a `pipeline_id to use in Azure Data factory`\n",
    "    - PRINT the pipeline ID after publish also\n",
    "- DONE.\n",
    "    \n",
    "\n",
    "Note: This notebook is called: `M11_v143_esml_regression_batch_scoring.ipynb` in the notebook_templates folder\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO for you: CONFIGURATION\n",
    "- 1) Change `p.active_model=11` to correct model number `1` if your model has that number.\n",
    "    - See  [lake_settings.json](./settings/project_specific/model/lake_settings.json) to find YOUR model number.\n",
    "- 2) After you run the cell [2) AUTO-GENERATE code: a snapshot folder](#2_generate_snapshot_folder), you need to add YOUR feature engineering logic\n",
    "    -  This code you probably already have, from the R&D phase, in this CUSTOMIZE cell in the notebook: [1_R&D_phase_M10_M11.ipynb](./1_quickstart/1_R&D_phase_M10_M11.ipynb)\n",
    "        - You need to this code to the `your_custom_code.py` after you have genereated the snapshot folder, for it to be reachable and uploaded at pipeline creation.\n",
    "        - Tip: You can CREATE A CLASS, and add static methods, e.g. `ds01_process_in2silver(dataframe1)`  in the `your_custom_code.py` \n",
    "- 3) Now you have your code in the `your_custom_code.py`, then you need to reference that code from the auto-generated pipeline-steps files such as `in2silver_ds01_diabetes.py`\n",
    "    - Note: This snapshot folder will not exist, until you have run the first 2 cells in this notebook, or after this cell has run the cell [2) AUTO-GENERATE code: a snapshot folder](#2_generate_snapshot_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Initiate ESMLPipelineFactory (Always run thic CELL below)\n",
    "- To attach ESML controlplane to your project\n",
    "- To point at `template-data` for the pipeline to know the schema of data.\n",
    "    - NB! Azure machine learning pipelines need sample data. You need to have sample-data underneath the datalake folder structure:\n",
    "    - `1` is recommended for `model_version folder`\n",
    "    - `1000-01-01 00:00:00.243860` is recommended for `date_folder`\n",
    "    - Example: project002/11_diabetes_model_reg/inference/`1`/ds01_diabetes/in/dev/`1000/01/01/`\n",
    "- To init the ESMLPipelinefactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lake_settings.json with ESML version 1.4 - Models array support including LABEL\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../azure-enterprise-scale-ml/esml/common/\")\n",
    "from esml import ESMLProject\n",
    "from baselayer_azure_ml_pipeline import ESMLPipelineFactory, esml_pipeline_types\n",
    " \n",
    "p = ESMLProject() # Will search in ROOT for your copied SETTINGS folder '../settings/model/active/active_scoring_in_folder.json',\n",
    "p.inference_mode = True\n",
    "p.active_model = 11 # 10=titanic , 11=Diabetes\n",
    "p_factory = ESMLPipelineFactory(p)\n",
    "\n",
    "# Azure machine learling pipelines need sample data to know schema\n",
    "# model_version= 0 meaning that ESML will find LATEST PROMOTED/best model, and not use a specific Model.versio to score with. It will read data from .../inference/0/... folder\n",
    "model_version = 5 # 5 = DatabricksPipeline, 36=AutoMLStep, 16=PythonPipeline, 1-4 = AtomlRun (No pipeline)\n",
    "p_factory.batch_pipeline_parameters[0].default_value = model_version \n",
    "\n",
    "training_datefolder = '1000-01-01 10:35:01.243860' # Will override active_scoring_in_folder.json'\n",
    "p_factory.batch_pipeline_parameters[1].default_value = training_datefolder # overrides ESMLProject.date_scoring_folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"One time a day\" - the below is needed to be done, to ensure Azure ML v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"NB! The below command you only need to run 1 time a day - then you can disable this cell. comment the code lines\")\n",
    "print(\"\")\n",
    "# Set LEGACY mode - Azure ML v1 - since private link and DatabricksStep\n",
    "p.ws = p.get_workspace_from_config()\n",
    "p.ws.update(v1_legacy_mode=True) # If you happen to have a workspace in v2 mode, and want to change back to v1 legacy mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) `AUTO-GENERATE code: a snapshot folder`\n",
    "<a id='2_generate_snapshot_folder'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did NOT overwrite script-files with template-files such as 'scoring_gold.py', since overwrite_if_exists=False\n"
     ]
    }
   ],
   "source": [
    "## Generate CODE - then edit it to get correct environments\n",
    "p_factory.create_dataset_scripts_from_template(overwrite_if_exists=False) # Do this once, then edit them manually. overwrite_if_exists=False is DEFAULT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) `BUILDS the pipeline, and RUN the pipeline (smoke testing)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take note on the `esml_pipeline_types` below, of type: esml_pipeline_types.`IN_2_GOLD_SCORING`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GEN2 as Datastore\n",
      "use_project_sp_2_mount: True\n",
      "Environment ESML-AzureML-144-AutoML_126 exists\n",
      "Using Azure ML Environment: 'ESML-AzureML-144-AutoML_126' as primary environment for PythonScript Steps\n",
      "ESML will auto-create a compute...\n",
      "Note: OVERRIDING enterprise performance settings with project specifics. (to change, set flag in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=False)\n",
      "Using a model specific cluster, per configuration in project specific settings, (the integer of 'model_number' is the base for the name)\n",
      "Note: OVERRIDING enterprise performance settings with project specifics. (to change, set flag in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=False)\n",
      "Found existing cluster prj001-m11-dev for project and environment, using it.\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n",
      "image_build_compute = prj001-m11-dev\n",
      "Initiated DEFAULT compute - for DATASETS\n",
      "Reusing existing compute...\n",
      "Reusing existing compute...\n",
      "ESML regular mode\n",
      "datasets_list_with_dbx \n",
      "create_gold_to_score_step: inference_mode=True\n",
      "Adding inference step, creating...\n",
      "ESML INFO: SPECIFIC (maybe leading) MODEL: model_version in-parameter from user is PipelineParameter_Name:esml_inference_model_version_Default:5, hence no guarantee that BEST LATEST PROMOTED model.version is used. User decided version is used\n",
      "ESML INFO: model_version is PipelineParameter_Name:esml_inference_model_version_Default:5 e.g. batch_pipeline_parameters[0] = PipelineParameter_Name:esml_inference_model_version_Default:5 meaning, it will fetch model.version=PipelineParameter_Name:esml_inference_model_version_Default:5, and READ IN DATA from .../inference/PipelineParameter_Name:esml_inference_model_version_Default:5/ folder structure\n",
      " - 1) GOLD to SCORE will be saved temporary by pipeline here: .../inference/0/gold/dev/*.parquet (e.g. overwritten each run)\n",
      " - 2) SCORED GOLD data will be saved in .../inference/PipelineParameter_Name:esml_inference_model_version_Default:5/scored/dev/run_id/*.parquet (e.g. not overwritten since run_folder, saved for each run)\n",
      " - 3) LATEST SCORED GOLD data will be saved in .../inference/0/scored/dev/run_id/*.parquet (e.g. not overwritten since run_folder. version_folder, for easy retrieval from external systems)\n"
     ]
    }
   ],
   "source": [
    "## BUILD\n",
    "batch_pipeline = p_factory.create_batch_pipeline(esml_pipeline_types.IN_2_GOLD_SCORING) # Note the esml_pipeline_types"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4a) `Execute the pipeline (smoke testing)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execute_pipeline (scoring): Inference_mode: 1\n",
      "-Scoring data, default value 1000-01-01 10:35:01.243860\n",
      "Adding pipeline parameters\n",
      "Created step IN 2 SILVER - ds01_diabetes [846d43ed][0a355e02-dd47-4150-8bf0-aabb29f1d3f3], (This step will run and generate new outputs)\n",
      "Created step IN 2 SILVER - ds02_other [6cd4cea6][0f53b9ca-97f7-408b-8030-3884205b6fdf], (This step will run and generate new outputs)\n",
      "Created step SILVER MERGED 2 GOLD [8c095514][87d709b8-7d3a-4901-b7cb-d8e595afcba9], (This step will run and generate new outputs)\n",
      "Created step SCORING GOLD [e4899d86][7fc1be0c-fc76-463c-958e-379d36566f44], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun d910a22e-a254-4e15-a103-2c045b41e568\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/d910a22e-a254-4e15-a103-2c045b41e568?wsid=/subscriptions/50ef5835-c45a-4c2e-a596-2a9e0e2a0a33/resourcegroups/dc-heroes-esml-project001-weu-DEV-001-rg/workspaces/aml-prj001-weu-DEV-001&tid=846f02b7-f92a-4053-9a99-094e5ba2e1a4\n",
      "Pipeline submitted for execution!\n",
      " ### \n",
      "PipelineRunId: d910a22e-a254-4e15-a103-2c045b41e568\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/d910a22e-a254-4e15-a103-2c045b41e568?wsid=/subscriptions/50ef5835-c45a-4c2e-a596-2a9e0e2a0a33/resourcegroups/dc-heroes-esml-project001-weu-DEV-001-rg/workspaces/aml-prj001-weu-DEV-001&tid=846f02b7-f92a-4053-9a99-094e5ba2e1a4\n"
     ]
    }
   ],
   "source": [
    "## RUN for smoke testing purpose, to see that it works during runtime\n",
    "pipeline_run = p_factory.execute_pipeline(batch_pipeline) # Tip: Pointing at the wrong folder for the sample data is the most common error \"StreamAccessException\"\n",
    "pipeline_run.wait_for_completion(show_output=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4b) See the RESULTS: Metadata about SCORING & actual SCORING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pipeline_run_id</th>\n",
       "      <th>scored_gold_path</th>\n",
       "      <th>date_in_parameter</th>\n",
       "      <th>date_at_pipeline_run</th>\n",
       "      <th>model_version</th>\n",
       "      <th>used_model_version</th>\n",
       "      <th>used_model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34cdc542-6b8e-454d-afa5-47fb243e48e6</td>\n",
       "      <td>projects/project001/11_diabetes_model_reg/inference/0/scored/dev/1000/01/01/34cdc542-6b8e-454d-afa5-47fb243e48e6/</td>\n",
       "      <td>1000-01-01 10:35:01.243860</td>\n",
       "      <td>2023-01-13 15:29:47.611164</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11_diabetes_model_reg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        pipeline_run_id  \\\n",
       "0  34cdc542-6b8e-454d-afa5-47fb243e48e6   \n",
       "\n",
       "                                                                                                    scored_gold_path  \\\n",
       "0  projects/project001/11_diabetes_model_reg/inference/0/scored/dev/1000/01/01/34cdc542-6b8e-454d-afa5-47fb243e48e6/   \n",
       "\n",
       "            date_in_parameter        date_at_pipeline_run model_version  \\\n",
       "0  1000-01-01 10:35:01.243860  2023-01-13 15:29:47.611164             0   \n",
       "\n",
       "  used_model_version        used_model_name  \n",
       "0                  2  11_diabetes_model_reg  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "ds_name =\"{}_GOLD_SCORED_RUNINFO\".format(p.ModelAlias)\n",
    "meta_ds= Dataset.get_by_name(workspace=p.ws,name=ds_name, version='latest')\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "meta_ds.to_pandas_dataframe().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds_name M11_GOLD_SCORED\n",
      "TabularDataset = True\n",
      "        AGE       SEX       BMI        BP        S1        S2        S3  \\\n",
      "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
      "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
      "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
      "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
      "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
      "\n",
      "         S4        S5        S6  prediction  \n",
      "0 -0.002592  0.019908 -0.017646  211.647599  \n",
      "1 -0.039493 -0.068330 -0.092204   49.926834  \n",
      "2 -0.002592  0.002864 -0.025930  224.845740  \n",
      "3  0.034309  0.022692 -0.009362  160.014210  \n",
      "4 -0.002592 -0.031991 -0.046641   91.652218  \n"
     ]
    }
   ],
   "source": [
    "from azureml.data import FileDataset\n",
    "import pandas as pd\n",
    "ds_name =\"{}_GOLD_SCORED\".format(p.ModelAlias)\n",
    "print(\"ds_name\", ds_name)\n",
    "meta_ds= Dataset.get_by_name(workspace=p.ws,name=ds_name, version='latest')\n",
    "\n",
    "if(type(meta_ds) is FileDataset):\n",
    "    print(\"FileDataset = True\")\n",
    "    path = meta_ds.take(1).download('./data_temp/', overwrite=True)\n",
    "    #df = pd.DataFrame(meta_ds.to_path())\n",
    "    df = pd.DataFrame(path)\n",
    "    df.head()\n",
    "else:\n",
    "    print(\"TabularDataset = True\")\n",
    "    print(meta_ds.to_pandas_dataframe().head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) PUBLISH the TRAINING pipeline & PRINT its ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PUBLISH\n",
    "published_pipeline, endpoint = p_factory.publish_pipeline(batch_pipeline,\"_1\") # \"_1\" is optional    to create a NEW pipeline with 0 history, not ADD version to existing pipe & endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRINT: Get info to use in Azure data factory\n",
    "- `published_pipeline.id` (if private Azure ML workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2) Fetch scored data: Below needed for Azure Data factory PIPELINE activity (Pipeline OR Endpoint. Choose the latter\n",
      "- Endpoint ID\n",
      "Endpoint ID:  aedd1e4c-a3eb-40ae-b9c2-a93b6b576523\n",
      "Endpoint Name:  11_diabetes_model_reg_pipe_IN_2_GOLD_SCORING_EP_1\n",
      "Experiment name:  11_diabetes_model_reg_pipe_IN_2_GOLD_SCORING\n",
      "In AZURE DATA FACTORY - This is the ID you need, if using PRIVATE LINK, private Azure ML workspace.\n",
      "-You need PIPELINE id, not pipeline ENDPOINT ID ( since cannot be chosen in Azure data factory if private Azure ML)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1930f46b-69ab-4aec-9e93-f6d5998c9e7c'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"2) Fetch scored data: Below needed for Azure Data factory PIPELINE activity (Pipeline OR Endpoint. Choose the latter\") \n",
    "print (\"- Endpoint ID\")\n",
    "print(\"Endpoint ID:  {}\".format(endpoint.id))\n",
    "print(\"Endpoint Name:  {}\".format(endpoint.name))\n",
    "print(\"Experiment name:  {}\".format(p_factory.experiment_name))\n",
    "\n",
    "print(\"In AZURE DATA FACTORY - This is the ID you need, if using PRIVATE LINK, private Azure ML workspace.\")\n",
    "print(\"-You need PIPELINE id, not pipeline ENDPOINT ID ( since cannot be chosen in Azure data factory if private Azure ML)\")\n",
    "published_pipeline.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # DONE! Next step would be\n",
    "\n",
    " - Q: `Next step in PRODUCTION phaase after the 2a and 3a or 3b notebooks are done?`\n",
    "\n",
    "1) Go to your ESMLProjects `Azure data factory`, and use the `ESML DataOps templates` (Azure data factory templates) for `IN_2_GOLD_SCORING`\n",
    "    - azure-enterprise-scale-ml\\copy_my_subfolders_to_my_grandparent\\adf\\v1_3\\PROJECT000\\LakeOnly\\`STEP03_IN_2_GOLD_SCORING.zip`\n",
    "2) Go to the next notebook `mlops` folder, to setup `CI/CD` in Azure Devops\n",
    "    - Import this in Azure devops\n",
    "        azure-enterprise-scale-ml\\copy_my_subfolders_to_my_grandparent\\mlops\\01_template_v14\\azure-devops-build-pipeline-to-import\\\\`ESML-v14-project002_M11-DevTest.json`\n",
    "    - Change the Azure Devops `VARIABLES` for service principle, tenant, etc.\n",
    "    - Change parameters in the `inlince Azure CLI script` to correct model you want to work with, and the correct data you want to train with, or score.\n",
    "        - File: `31-deploy_and_smoketest_batch_scoring.py`\n",
    "        - INLINE code: `--esml_model_number 11 --esml_date_utc \"1000-01-01 10:35:01.243860\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure_automl_esml_v148",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "4799850f3103fb5d9644ce9433832c953591f6eac3309b593d58ecf6d126f819"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
