{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3612jvsc74a57bd03fec2c5a411dce07235ef28c8752b6cecf1f94423de7e7c24e62fc38b1bc47de",
   "display_name": "Python 3.6.12 64-bit ('azure_automl': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "![](../azure-enterprise-scale-ml/esml/images/split_gold_and_train_automl_small.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "# ESML - `AutoMLFactory` and `ComputeFactory`\n",
    "\n",
    "## PROJECT + DATA CONCEPTS + ENTERPRISE Datalake Design + DEV->PROD MLOps\n",
    "- `1)ESML Project`: The ONLY thing you need to remember is your `Project number` (and `BRONZE, SILVER, GOLD` concept )\n",
    "   -  ...`read earlier notebook\n",
    "## ENTERPRISE Deployment of Models & Governance - MLOps  at scale\n",
    "- `3) DEV->TEST-PROD` (configs, compute, performance)\n",
    "    - ESML has config for 3 environemnts: Easy DEPLOY model across subscriptions and Azure ML Studio workspaces \n",
    "        - Save costs & time: \n",
    "            - `DEV` has cheaper compute performance for TRAIN and INFERENCE (batch, AKS)\n",
    "            - `DEV` has Quick-debug ML training (fast training...VS good scoring in TEST and PROD)\n",
    "        - How? ESML `AutoMLFactory` and `ComputeFactory`\n",
    "        - Where to config these?\n",
    "            - settings/dev_test_prod/`dev_test_prod_settings.json`\n",
    "            - settings/dev_test_prod/`train/*/automl/*`\n",
    "\n",
    "## SAVE COST in R&D MODE\n",
    "    `- EMSL has R&D mode: Set p.rnd=True \n",
    "        - Versioning on dataset will be turned off (save storage & cluttering in Azure)\n",
    "        - Save cost & time \"while debuggin\" building codebase: \n",
    "            - In R&D mode the IN data will have a filter to use only 20% of the data.\n",
    "            - Meaning - You can use a SMALL compute, since less data\n",
    "            - .....when your codebase is ready for the real TRAINING, switch COMPUTE and turnoff p.rnd = False\n",
    "\n",
    "---\n",
    "**Q:Howto work with different environemnts?** \n",
    "- A: *Train in TEST instead of DEV like below:*  \n",
    ">\n",
    "`\n",
    "print(p.dev_test_prod)  \n",
    "ws_test = p.get_other_workspace(p.dev_test_prod)  \n",
    "datastore = p.init(ws_test)  \n",
    "`\n",
    "\n",
    "https://medium.com/analytics-vidhya/the-ultimate-markdown-guide-for-jupyter-notebook-d5e5abf728fd"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(\"../azure-enterprise-scale-ml/esml/common/\"))  # NOQA: E402\n",
    "from esml import ESMLDataset, ESMLProject\n",
    "p = ESMLProject() #  self-booting config ..... p = ESMLProject(esml_settings,env_settings, security_settings) # read from config\n",
    "p.inference_mode = False # We want \"TRAIN\" mode\n",
    "p.describe()"
   ]
  },
  {
   "source": [
    "# Azure ML Studio Workspace\n",
    "- ESML will `Automap` and `Autoregister` Azure ML Datasets as: `IN, SILVER, BRONZE, GOLD`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core \n",
    "from azureml.core import Workspace\n",
    "ws = p.get_workspace_from_config()\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.unregister_all_datasets(ws) # For DEMO purpose\n",
    "p.init(ws)"
   ]
  },
  {
   "source": [
    "# ESML `GOLD` Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_01 = p.DatasetByName(\"ds01_diabetes\")\n",
    "print(ds_01.InData.name)\n",
    "print(ds_01.Bronze.name)\n",
    "print(ds_01.Silver.name)\n",
    "#print(p.Gold.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.dataset_list[1].Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01 = ds_01.Silver.to_pandas_dataframe()\n",
    "\n",
    "ds_02 = ds_01 = p.DatasetByName(\"ds02_other\")\n",
    "df_02 = ds_02.Silver.to_pandas_dataframe()\n",
    "df_gold1_join = df_01.join(df_02) # left join -> NULL on df_02\n",
    "print(\"Diabetes shape: \", df_01.shape)\n",
    "print(df_gold1_join.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_gold_v1 = p.save_gold(df_01)"
   ]
  },
  {
   "source": [
    "# Look at `GOLD` vLatest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = p.Gold.to_pandas_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p.rnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"Y\"\n",
    "train_6, validate_set_2, test_set_2 = p.split_gold_3(0.6, label)\n",
    "print(\" Q:  But...Why add LABEL info when splitting for TRAIN?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"...This is why:\")\n",
    "X_test, y_test, tags = p.get_gold_validate_Xy() # Version is default latest\n",
    "print(tags)"
   ]
  },
  {
   "source": [
    "## 3B) ESML TRAIN model - via PIPELINE (reuse, call via REST, etc..)\n",
    "- `AutoMLFactory, ComputeFactory`\n",
    "- Get `Train COMPUTE` for `X` environment\n",
    "- Get `Train Hyperparameters` for `X` environment (less crossvalidations in DEV etc)\n",
    "- Splits into versioned `train, validate, test` sets from GOLD, `and register them` as Azure ML datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(\"../common/\"))  # NOQA: E402\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from baselayer_azure_ml import AutoMLFactory, ComputeFactory, azure_metric_regression, azure_metric_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "automl_performance_config = p.get_automl_performance_config()\n",
    "aml_compute = p.get_training_aml_compute(ws)\n",
    "\n",
    "label = \"Y\" \n",
    "# Automatically registers dataframes in AZURE as M03_GOLD_TRAIN | M03_GOLD_VALIDATE | M03_GOLD_TEST # Alt: train,testv= p.Gold.random_split(percentage=0.8, seed=23)\n",
    "train_6, validate_set_2, test_set_2 = p.split_gold_3(0.6,label)\n",
    "\n",
    "automl_config = AutoMLConfig(task = 'regression',\n",
    "                             compute_target = aml_compute,\n",
    "                             primary_metric = azure_metric_regression.MAE, #  'normalized_mean_absolute_error, normalized_root_mean_squared_error, spearman_correlation, r2_score'\n",
    "                             experiment_exit_score = '0.208', # DEMO purpose\n",
    "                             training_data = p.GoldTrain,   # This is the Azure ML Dataset representation fo 'train_6' pandas dataframe\n",
    "                             label_column_name = label,\n",
    "                             **automl_performance_config\n",
    "                            )\n",
    "best_run, fitted_model, exp = AutoMLFactory(p).train_pipeline(automl_config)"
   ]
  },
  {
   "source": [
    "## 3A) ESML TRAIN model\n",
    "- `AutoMLFactory, ComputeFactory`\n",
    "- Get `Train COMPUTE` for `X` environment\n",
    "- Get `Train Hyperparameters` for `X` environment (less crossvalidations in DEV etc)\n",
    "- Splits into versioned `train, validate, test` sets from GOLD, `and register them` as Azure ML datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_performance_config = p.get_automl_performance_config()\n",
    "aml_compute = p.get_training_aml_compute(ws)\n",
    "\n",
    "label = \"Y\" \n",
    "# Automatically registers dataframes in AZURE as M03_GOLD_TRAIN | M03_GOLD_VALIDATE | M03_GOLD_TEST # Alt: train,testv= p.Gold.random_split(percentage=0.8, seed=23)\n",
    "train_6, validate_set_2, test_set_2 = p.split_gold_3(0.6,label)\n",
    "\n",
    "automl_config = AutoMLConfig(task = 'regression',\n",
    "                             compute_target = aml_compute,\n",
    "                             primary_metric = azure_metric_regression.RMSE,\n",
    "                             training_data = p.GoldTrain, # is 'train_6' pandas dataframe, but as an Azure ML Dataset\n",
    "                             experiment_exit_score = '0.208', # DEMO purpose\n",
    "                             label_column_name = label,\n",
    "                             **automl_performance_config\n",
    "                            )\n",
    "\n",
    "via_pipeline = False\n",
    "best_run, fitted_model, experiment = AutoMLFactory(p).train_pipeline(automl_config) if via_pipeline else AutoMLFactory(p).train_as_run(automl_config)"
   ]
  },
  {
   "source": [
    "## 4a) ESML Scoring compare: Promote model or not? Register\n",
    "- `IF` newly trained model in `current` environment scores BETTER than existing model in `target` environment, then `new model` can be registered and promoted.\n",
    "-  `ValidationSet` comparison of offline/previous `AutoML run` for `DEV` environment\n",
    "- For `DEV`, `TEST` or `PROD` environment\n",
    "- Future roadmap: Also include `TestSet SCORING` comparison"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baselayer_azure_ml import AutoMLFactory\n",
    "p.dev_test_prod = \"dev\" # Current env, new unregistered model A to validate\n",
    "target_env = \"dev\" # Target env. Existing registered model B - Does Model A score better than Model B?\n",
    "\n",
    "print(\"If new model scores better, we can register this in DEV/TEST/PROD\")\n",
    "print(\"If new model we trained was DEV workspace, we can register it DEV - or in TEST subscription/workpace.\")\n",
    "\n",
    "promote, m1_name, r1_id, m2_name, r2_run_id = AutoMLFactory(p).compare_scoring_current_vs_new_model(target_env)\n",
    "\n",
    "print(\"Promote model?  {}\".format(promote))\n",
    "print(\"New Model 1: {}\".format(m1_name))\n",
    "print(\"Existing Model: {} in environment {}\".format(m2_name,target_env))\n",
    "\n",
    "if (promote and p.dev_test_prod == target_env ): # Can only register a model in same workspace (test->test) - need to retrain if going from dev->test\n",
    "    AutoMLFactory(p).register_active_model(target_env)\n"
   ]
  },
  {
   "source": [
    "### ..Model compared, promoted, register - ready for deployment"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 4b) ESML Loadtesting performance & Cost estimation\n",
    "- Using ESML GOLD_TEST Dataset for AutoML to see which algorithm that is fastest, smallest size footprint\n",
    "- Using ESML GOLD_SCORING Dataset, to see `COST` of a `Training run`\n",
    "- ...For different environments: `DEV`, `TEST` or `PROD` environment\n",
    "\n",
    "GOTO Notebook [`esml_howto_5_load_test_and_predict_cost`](./esml_howto_5_load_test_and_predict_cost.ipynb)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 5a) ESML - Deploy ONLINE to AKS & Score BATCH\n",
    "- Deploy \"offline\" from old `AutoML run` for `DEV` environment\n",
    "- To →  `DEV`, `TEST` or `PROD` environment\n",
    "\n",
    "\n",
    "Compare model in DEV with TEST & Register  - GOTO Notebook [`esml_howto_3_compare_and_register`](./esml_howto_3_compare_and_register.ipynb)\n",
    "\n",
    "Deploy & Score: GOTO Notebook [`esml_howto_3_deploy_score`](./esml_howto_3_deploy_score.ipynb)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 5b) ESML `Deploy BATCH` pipeline\n",
    "- Deploy same model \"offline / previous\" `AutoML Run` for `DEV` environment\n",
    "- To →  `DEV`, `TEST` or `PROD` environment\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}