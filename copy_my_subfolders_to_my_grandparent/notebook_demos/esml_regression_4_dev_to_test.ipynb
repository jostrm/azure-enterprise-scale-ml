{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('azure_automl': conda)"
  },
  "interpreter": {
   "hash": "3fec2c5a411dce07235ef28c8752b6cecf1f94423de7e7c24e62fc38b1bc47de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# ESML - accelerator: \"Connect to BOTH DEV and TEST workspaces\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from azureml.core import Workspace\n",
    "sys.path.append(os.path.abspath(\"../azure-enterprise-scale-ml/esml/common/\"))  # NOQA: E402\n",
    "from esml import ESMLDataset, ESMLProject\n",
    "\n",
    "p = ESMLProject() # self-aware about its config sources, will search in ROOT for your copied SETTINGS folder '../../../settings'\n",
    "p.ws = p.get_workspace_from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "msft-weu-DEV-eap-proj02_ai-amls\n",
      "msft-weu-TEST-eap-proj02_ai-amls\n"
     ]
    }
   ],
   "source": [
    "print(p.ws.name)\n",
    "ws2 = p.get_other_workspace(\"test\") # Fetch ws2 via SP, from default keyvault in ws1\n",
    "print(ws2.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Inference version: 1\n\n - ds01_diabetes\nprojects/project002/03_diabetes_model_reg/inference/1/ds01_diabetes/in/dev/2021/06/08/\nprojects/project002/03_diabetes_model_reg/inference/1/ds01_diabetes/out/bronze/dev/\nprojects/project002/03_diabetes_model_reg/inference/1/ds01_diabetes/out/silver/dev/\n\n - ds02_other\nprojects/project002/03_diabetes_model_reg/inference/1/ds02_other/in/dev/2021/06/08/\nprojects/project002/03_diabetes_model_reg/inference/1/ds02_other/out/bronze/dev/\nprojects/project002/03_diabetes_model_reg/inference/1/ds02_other/out/silver/dev/\n \n\nTraining GOLD (p.GoldPath)\nprojects/project002/03_diabetes_model_reg/inference/1/gold/dev/\n \n\n[A) USAGE]: to_score_folder, scored_folder, date_folder = p.get_gold_scored_unique_path()\nA)INFERENCE ONLINE: GOLD to score (example if realtime - today)\nprojects/project002/03_diabetes_model_reg/inference/1/gold/dev/2021_06_21/899e0ca7175f44baad44a099ddd902c3/\n \n\nA)INFERENCE ONLINE: GOLD scored (example if realtime today)\nprojects/project002/03_diabetes_model_reg/inference/1/scored/dev/2021_06_21/899e0ca7175f44baad44a099ddd902c3/\n \n\n[B) USAGE]: to_score_folder_batch, scored_folder, date_folder = p.get_gold_scored_unique_path(p.date_scoring_folder)\nB)INFERENCE BATCH: GOLD to score (example batch, datetime from config)\nprojects/project002/03_diabetes_model_reg/inference/1/gold/dev/2021_06_08/2da1d856f4454f08ab84e8d3a0958d1c/\n \n\nB)INFERENCE BATCH: GOLD scored (example batch, datetime from config)\nprojects/project002/03_diabetes_model_reg/inference/1/scored/dev/2021_06_08/2da1d856f4454f08ab84e8d3a0958d1c/\n \n\nC) INFERENCE BATCH (SCENARIO 2): TODAY I scored data from X days AGO  (second datefolder from config - X days ago)\nprojects/project002/03_diabetes_model_reg/inference/1/gold/dev/2021_06_08/2da1d856f4454f08ab84e8d3a0958d1c/2021_06_08/\nprojects/project002/03_diabetes_model_reg/inference/1/scored/dev/2021_06_08/2da1d856f4454f08ab84e8d3a0958d1c/2021_06_08/\n \n\nENVIRONMENT - DEV, TEST, or PROD?  [USAGE: p.dev_test_prod]\nACTIVE ENVIRONMENT = dev\nACTIVE subscription = ca0a8c40-b06a-4e4e-8434-63c03a1dee34\n- MSFT-WEU-EAP_PROJECT02_AI-DEV-RG\n- msft-weu-DEV-eap-proj02_ai-amls\n- westeurope\n- MSFT-WEU-EAP_CMN_AI-DEV-RG\nActive vNet: msft-weu-dev-cmnai-vnet\nActive SubNet: \n[USAGE] for the above: p.vNetForActiveEnvironment()\nActive Lake (storage account)  msftweudevcmnai2\n[USAGE] for the above: p.getLakeForActiveEnvironment()\nAML for docker: True\n"
     ]
    }
   ],
   "source": [
    "p.dev_test_prod = \"dev\"\n",
    "p.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "...\n",
      "Using GEN2 as Datastore\n",
      "Searching for setting in ESML datalake...\n",
      "ESML in-folder settings override = TRUE \n",
      " - Found settings in the ESML AutoLake  [active_in_folder.json,active_scoring_in_folder.json], to override ArgParse/GIT config with.\n",
      " - TRAIN in date:  2021/01/01\n",
      " - INFERENCE in date: 2021/06/08 and ModelVersion to score with: 1 (0=latest)\n",
      "\n",
      "Inference mode (False = Training mode): True\n",
      "Load data as Datasets....\n",
      "ds01_diabetes\n",
      "ds02_other\n",
      "\n",
      "####### Automap & Autoregister - SUCCESS!\n",
      "1) Auto mapped 2 ESML Dataset with registered Azure ML Datasets (potentially all 3: IN,BRONZE, SILVER) in Datastore project002 \n",
      "\n",
      "Dataset 'ds01_diabetes' status:\n",
      " - IN_Folder_has_files\n",
      " - BRONZE_Folder_has_files\n",
      " - SILVER_Folder_has_files\n",
      "Dataset 'ds02_other' status:\n",
      " - IN_Folder_has_files\n",
      " - BRONZE_Folder_has_files\n",
      " - SILVER_Folder_has_files\n",
      "\n",
      "2) Registered each Dataset with suffixes (_IN, _BRONZE, _SILVER) \n",
      " Tip: Use ESMLProject.Datasets list or .DatasetByName(myDatasetName) to read/write\n",
      "#######\n"
     ]
    }
   ],
   "source": [
    "datastore1 = p.init(p.ws) # DEV WS (main workspace - always start at DEV...to get TEST, or PROD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "...\n",
      "Using GEN2 as Datastore\n",
      "Searching for setting in ESML datalake...\n",
      "ESML in-folder settings override = TRUE \n",
      " - Found settings in the ESML AutoLake  [active_in_folder.json,active_scoring_in_folder.json], to override ArgParse/GIT config with.\n",
      " - TRAIN in date:  2021/01/01\n",
      " - INFERENCE in date: 2021/06/08 and ModelVersion to score with: 1 (0=latest)\n",
      "\n",
      "Inference mode (False = Training mode): True\n",
      "Load data as Datasets....\n",
      "ds01_diabetes\n",
      "ds02_other\n",
      "\n",
      "####### Automap & Autoregister - SUCCESS!\n",
      "1) Auto mapped 2 ESML Dataset with registered Azure ML Datasets (potentially all 3: IN,BRONZE, SILVER) in Datastore project002 \n",
      "\n",
      "Dataset 'ds01_diabetes' status:\n",
      " - IN_Folder_has_files\n",
      " - BRONZE_Folder_has_files\n",
      " - SILVER_Folder_has_files\n",
      "Dataset 'ds02_other' status:\n",
      " - IN_Folder_has_files\n",
      " - BRONZE_Folder_has_files\n",
      " - SILVER_Folder_has_files\n",
      "\n",
      "2) Registered each Dataset with suffixes (_IN, _BRONZE, _SILVER) \n",
      " Tip: Use ESMLProject.Datasets list or .DatasetByName(myDatasetName) to read/write\n",
      "#######\n"
     ]
    }
   ],
   "source": [
    "datastore2 = p.init(ws2) # TEST workspace"
   ]
  },
  {
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "auth = InteractiveLoginAuthentication(tenant_id = p.tenant)\n",
    "ws = Workspace.get(name = p.workspace_name,subscription_id = p.subscription_id,resource_group = p.resource_group,auth=auth)\n",
    "ws.write_config(path=\".\", file_name=\"../../ws_config.json\")\n",
    "\n",
    "ws = Workspace.from_config(\"../ws_config.json\") # Reads config.json "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# TRAIN MODEL in `TEST` -  First `SAVE a GOLD`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading ./common/temp_data/project002/Gold\\gold.parquet\n",
      "Uploaded ./common/temp_data/project002/Gold\\gold.parquet, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        AGE      SEX       BMI        BP        S1        S2        S3  \\\n",
       "0  0.038076  0.05068  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1  0.085299  0.05068  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "2  0.063504  0.05068 -0.001895  0.066630  0.090620  0.108914  0.022869   \n",
       "3  0.041708  0.05068  0.061696 -0.040099 -0.013953  0.006202 -0.028674   \n",
       "4  0.027178  0.05068  0.017506 -0.033214 -0.007073  0.045972 -0.065491   \n",
       "\n",
       "         S4        S5        S6      Y  \n",
       "0 -0.002592  0.019908 -0.017646  151.0  \n",
       "1 -0.002592  0.002864 -0.025930  141.0  \n",
       "2  0.017703 -0.035817  0.003064   63.0  \n",
       "3 -0.002592 -0.014956  0.011349  110.0  \n",
       "4  0.071210 -0.096433 -0.059067   69.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AGE</th>\n      <th>SEX</th>\n      <th>BMI</th>\n      <th>BP</th>\n      <th>S1</th>\n      <th>S2</th>\n      <th>S3</th>\n      <th>S4</th>\n      <th>S5</th>\n      <th>S6</th>\n      <th>Y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.038076</td>\n      <td>0.05068</td>\n      <td>0.061696</td>\n      <td>0.021872</td>\n      <td>-0.044223</td>\n      <td>-0.034821</td>\n      <td>-0.043401</td>\n      <td>-0.002592</td>\n      <td>0.019908</td>\n      <td>-0.017646</td>\n      <td>151.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.085299</td>\n      <td>0.05068</td>\n      <td>0.044451</td>\n      <td>-0.005671</td>\n      <td>-0.045599</td>\n      <td>-0.034194</td>\n      <td>-0.032356</td>\n      <td>-0.002592</td>\n      <td>0.002864</td>\n      <td>-0.025930</td>\n      <td>141.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.063504</td>\n      <td>0.05068</td>\n      <td>-0.001895</td>\n      <td>0.066630</td>\n      <td>0.090620</td>\n      <td>0.108914</td>\n      <td>0.022869</td>\n      <td>0.017703</td>\n      <td>-0.035817</td>\n      <td>0.003064</td>\n      <td>63.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.041708</td>\n      <td>0.05068</td>\n      <td>0.061696</td>\n      <td>-0.040099</td>\n      <td>-0.013953</td>\n      <td>0.006202</td>\n      <td>-0.028674</td>\n      <td>-0.002592</td>\n      <td>-0.014956</td>\n      <td>0.011349</td>\n      <td>110.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.027178</td>\n      <td>0.05068</td>\n      <td>0.017506</td>\n      <td>-0.033214</td>\n      <td>-0.007073</td>\n      <td>0.045972</td>\n      <td>-0.065491</td>\n      <td>0.071210</td>\n      <td>-0.096433</td>\n      <td>-0.059067</td>\n      <td>69.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df_01 = p.DatasetByName(\"ds01_diabetes\").Silver.to_pandas_dataframe()\n",
    "ds_gold_v1 = p.save_gold(df_01)\n",
    "ds_gold_v1.to_pandas_dataframe().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.dev_test_prod = \"test\" # to get correct config, compute, etc"
   ]
  },
  {
   "source": [
    "\" Train in WS2 - TEST Workspace"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Found existing cluster for project and environment, use it.\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n",
      "Uploading an estimated of 1 files\n",
      "Uploading ./common/temp_data/project002/Gold/Train\\gold_train.parquet\n",
      "Uploaded ./common/temp_data/project002/Gold/Train\\gold_train.parquet, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n",
      "Uploading an estimated of 1 files\n",
      "Uploading ./common/temp_data/project002/Gold/Validate\\gold_validate.parquet\n",
      "Uploaded ./common/temp_data/project002/Gold/Validate\\gold_validate.parquet, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n",
      "Uploading an estimated of 1 files\n",
      "Uploading ./common/temp_data/project002/Gold/Test\\gold_test.parquet\n",
      "Uploaded ./common/temp_data/project002/Gold/Test\\gold_test.parquet, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n",
      "Experiment name: 03_diabetes_model_reg\n",
      "Azure ML Studio Workspace: Workspace.create(name='msft-weu-TEST-eap-proj02_ai-amls', subscription_id='ca0a8c40-b06a-4e4e-8434-63c03a1dee34', resource_group='MSFT-WEU-EAP_PROJECT02_AI-TEST-RG')\n",
      "Start training...\n",
      "Running on remote.\n",
      "No run_configuration provided, running on prj002-m03-test with default configuration\n",
      "Running on remote compute: prj002-m03-test\n",
      "Parent Run ID: AutoML_7094594e-8088-4e5c-b8ac-3570db68da4f\n",
      "\n",
      "Current status: FeaturesGeneration. Generating features for the dataset.\n",
      "Current status: DatasetCrossValidationSplit. Beginning model selection.\n",
      "Current status: ModelSelection. Beginning model selection.\n",
      "\n",
      "****************************************************************************************************\n",
      "DATA GUARDRAILS: \n",
      "\n",
      "TYPE:         Missing feature values imputation\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  No feature missing values were detected in the training data.\n",
      "              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "TYPE:         High cardinality feature detection\n",
      "STATUS:       PASSED\n",
      "DESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n",
      "              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n",
      "\n",
      "****************************************************************************************************\n",
      "\n",
      "****************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "****************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
      "         0   RobustScaler DecisionTree                      0:01:11       0.2493    0.2493\n",
      "         1   StandardScalerWrapper DecisionTree             0:01:09       0.2668    0.2493\n",
      "         2   RobustScaler DecisionTree                      0:01:07       0.2561    0.2493\n",
      "         3   MinMaxScaler DecisionTree                      0:01:09       0.2432    0.2432\n",
      "         4   StandardScalerWrapper DecisionTree             0:01:04       0.2464    0.2432\n",
      "         5   StandardScalerWrapper DecisionTree             0:01:10       0.2669    0.2432\n",
      "         6   RobustScaler DecisionTree                      0:04:33       0.2723    0.2432\n",
      "         7   RobustScaler DecisionTree                      0:01:06       0.2692    0.2432\n",
      "         8   RobustScaler DecisionTree                      0:01:11       0.2506    0.2432\n",
      "         9   StandardScalerWrapper DecisionTree             0:01:11       0.2501    0.2432\n",
      "        10   MinMaxScaler DecisionTree                      0:01:11       0.2560    0.2432\n",
      "        11   MinMaxScaler DecisionTree                      0:01:05       0.2715    0.2432\n",
      "        12   RobustScaler DecisionTree                      0:01:03       0.2657    0.2432\n",
      "        13   StandardScalerWrapper DecisionTree             0:01:16       0.2668    0.2432\n",
      "        14   MinMaxScaler DecisionTree                      0:01:12       0.2506    0.2432\n",
      "        15   MinMaxScaler DecisionTree                      0:01:11       0.2299    0.2299\n",
      "        16   MinMaxScaler DecisionTree                      0:01:12       0.2542    0.2299\n",
      "        17   MinMaxScaler DecisionTree                      0:01:09       0.2766    0.2299\n",
      "        18   MinMaxScaler DecisionTree                      0:01:10       0.2471    0.2299\n",
      "        19   MinMaxScaler DecisionTree                      0:01:06       0.2274    0.2274\n",
      "        20   StandardScalerWrapper DecisionTree             0:01:06       0.2645    0.2274\n",
      "        21   SparseNormalizer DecisionTree                  0:01:11       0.2768    0.2274\n",
      "        22   MinMaxScaler DecisionTree                      0:01:13       0.2649    0.2274\n",
      "        23   RobustScaler DecisionTree                      0:01:16       0.2479    0.2274\n",
      "        24   StandardScalerWrapper DecisionTree             0:01:13       0.2679    0.2274\n",
      "        25   SparseNormalizer DecisionTree                  0:01:08       0.2611    0.2274\n",
      "        26   RobustScaler DecisionTree                      0:01:07       0.2544    0.2274\n",
      "        27   StandardScalerWrapper DecisionTree             0:01:10       0.2575    0.2274\n",
      "        28   MaxAbsScaler SGD                               0:01:18       0.2005    0.2005\n",
      "        29   StandardScalerWrapper DecisionTree             0:01:11       0.2353    0.2005\n",
      "        30   TruncatedSVDWrapper SGD                        0:01:02       0.6143    0.2005\n",
      "        31   MinMaxScaler DecisionTree                      0:01:04       0.2630    0.2005\n",
      "        32   RobustScaler DecisionTree                      0:01:09       0.2918    0.2005\n",
      "        33   StandardScalerWrapper DecisionTree             0:01:13       0.3000    0.2005\n",
      "        34   MaxAbsScaler DecisionTree                      0:01:08       0.2731    0.2005\n",
      "        35   TruncatedSVDWrapper SGD                        0:01:13       0.6544    0.2005\n",
      "        36   StandardScalerWrapper DecisionTree             0:01:06       0.2877    0.2005\n",
      "        37   MinMaxScaler DecisionTree                      0:01:10       0.2320    0.2005\n",
      "        38   MaxAbsScaler DecisionTree                      0:01:00       0.2688    0.2005\n",
      "        39    VotingEnsemble                                0:01:13       0.1829    0.1829\n",
      "        40    StackEnsemble                                 0:01:17       0.2017    0.1829\n",
      "WARNING:root:The version of the SDK does not match the version the model was trained on.\n",
      "WARNING:root:The consistency in the result may not be guaranteed.\n",
      "WARNING:root:Package:azureml-automl-core, training version:1.24.0, current version:1.21.0\n",
      "Package:azureml-automl-runtime, training version:1.24.0, current version:1.21.0\n",
      "Package:azureml-core, training version:1.24.0.post1, current version:1.21.0.post2\n",
      "Package:azureml-dataprep, training version:2.11.2, current version:2.8.2\n",
      "Package:azureml-dataprep-native, training version:30.0.0, current version:28.0.0\n",
      "Package:azureml-dataprep-rslex, training version:1.9.1, current version:1.6.0\n",
      "Package:azureml-dataset-runtime, training version:1.24.0, current version:1.21.0\n",
      "Package:azureml-defaults, training version:1.24.0, current version:1.21.0\n",
      "Package:azureml-interpret, training version:1.24.0, current version:1.21.0\n",
      "Package:azureml-pipeline-core, training version:1.24.0, current version:1.21.0\n",
      "Package:azureml-telemetry, training version:1.24.0, current version:1.21.0\n",
      "Package:azureml-train-automl-client, training version:1.24.0, current version:1.21.0\n",
      "Package:azureml-train-automl-runtime, training version:1.24.0, current version:1.21.0.post1\n",
      "WARNING:root:Below packages were used for model training but missing in current environment:\n",
      "WARNING:root:Package:azureml-mlflow, training version:1.24.0\n",
      "WARNING:root:Please ensure the version of your local conda dependencies match the version on which your model was trained in order to properly retrieve your model.\n",
      "Run(Experiment: 03_diabetes_model_reg,\n",
      "Id: AutoML_7094594e-8088-4e5c-b8ac-3570db68da4f_39,\n",
      "Type: azureml.scriptrun,\n",
      "Status: Completed)\n",
      "RegressionPipeline(pipeline=Pipeline(memory=None,\n",
      "                                     steps=[('datatransformer',\n",
      "                                             DataTransformer(enable_dnn=None,\n",
      "                                                             enable_feature_sweeping=None,\n",
      "                                                             feature_sweeping_config=None,\n",
      "                                                             feature_sweeping_timeout=None,\n",
      "                                                             featurization_config=None,\n",
      "                                                             force_text_dnn=None,\n",
      "                                                             is_cross_validation=None,\n",
      "                                                             is_onnx_compatible=None,\n",
      "                                                             logger=None,\n",
      "                                                             observer=None,\n",
      "                                                             task=None,\n",
      "                                                             working_dir=None)),\n",
      "                                            ('pre...\n",
      "                                                                                                                              min_samples_leaf=0.009523544173472464,\n",
      "                                                                                                                              min_samples_split=0.02180025323490051,\n",
      "                                                                                                                              min_weight_fraction_leaf=0.0,\n",
      "                                                                                                                              presort='deprecated',\n",
      "                                                                                                                              random_state=None,\n",
      "                                                                                                                              splitter='random'))],\n",
      "                                                                                                verbose=False))],\n",
      "                                                                          weights=[0.2857142857142857,\n",
      "                                                                                   0.14285714285714285,\n",
      "                                                                                   0.14285714285714285,\n",
      "                                                                                   0.07142857142857142,\n",
      "                                                                                   0.14285714285714285,\n",
      "                                                                                   0.14285714285714285,\n",
      "                                                                                   0.07142857142857142]))],\n",
      "                                     verbose=False),\n",
      "                   stddev=None)\n",
      "AutoML Model name: AutoML7094594e839\n"
     ]
    }
   ],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "from baselayer_azure_ml import AutoMLFactory, ComputeFactory\n",
    "\n",
    "automl_performance_config = p.get_automl_performance_config()\n",
    "aml_compute = p.get_training_aml_compute(ws2)\n",
    "\n",
    "label = \"Y\" \n",
    "# Returns PANDAS DF's (but also sets p.GoldTrain as Azure Dataset)\n",
    "train_6, validate_set_2, test_set_2 = p.split_gold_3(0.6,label) # Saves as M03_GOLD_TRAIN | M03_GOLD_VALIDATE | M03_GOLD_TEST # Alt: train,testv= p.Gold.random_split(percentage=0.8, seed=23)\n",
    "\n",
    "automl_config = AutoMLConfig(task = 'regression',\n",
    "                             compute_target = aml_compute,\n",
    "                             training_data = p.GoldTrain, # Azure Dataset\n",
    "                             label_column_name = label,\n",
    "                             **automl_performance_config\n",
    "                            )\n",
    "\n",
    "best_run, fitted_model, exp = AutoMLFactory(p).train(ws2,automl_config, p.model_folder_name, p.dev_test_prod)"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 4a) ESML Scoring compare: Promote model or not: `DEV -> TEST`?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.dev_test_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "what environment are we targeting? =  prod\n"
     ]
    }
   ],
   "source": [
    "from baselayer_azure_ml import AutoMLFactory, ComputeFactory\n",
    "p.dev_test_prod = \"test\"\n",
    "print(\"what environment are we targeting? =  {}\".format(p.dev_test_prod)) \n",
    "automl_performance_config = p.get_automl_performance_config()\n",
    "automl_performance_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baselayer_azure_ml import AutoMLFactory\n",
    "p.dev_test_prod = \"dev\" # Current env, new unregistered model A to validate\n",
    "target_env = \"test\" # Target env. Existing registered model B - Does Model A score better than Model B?\n",
    "\n",
    "print(\"SCORING DRIFT: If new model scores better in DEV (new data, or new code), we can promote this to TEST & PROD \\n\")\n",
    "print(\" - If new model scores better, we can register this in DEV/TEST/PROD\")\n",
    "print(\" - If new model we trained was DEV workspace, we can register it DEV - or in TEST subscription/workpace.\")\n",
    "\n",
    "promote, m1_name, r1_id, m2_name, r2_run_id = AutoMLFactory(p).compare_scoring_current_vs_new_model(target_env)\n",
    "\n",
    "print(\"New Model 1: {}\".format(m1_name))\n",
    "print(\"Existing Model: {} in environment {}\".format(m2_name,target_env))\n",
    "\n",
    "if (promote and p.dev_test_prod == target_env): # Can only register a model in same ACTIVE workspace (test->test) - need to retrain if going from dev->test\n",
    "    AutoMLFactory(p).register_active_model(target_env)\n"
   ]
  },
  {
   "source": [
    "# Register model \"1 cell code\" - no other dependency"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cleaning local temp for project\n",
      "Using GEN2 as Datastore\n",
      "ds01_diabetes\n",
      "Method upload_directory: This is an experimental method, and may change at any time.<br/>For more information, see https://aka.ms/azuremlexperimental.\n",
      "Uploading to datastore: <azureml.data.azure_data_lake_datastore.AzureDataLakeGen2Datastore object at 0x000001C6D50F3CC0> \n",
      "From: ./common/temp_data/project002/ds01_diabetes/Bronze/ \n",
      "To: master/1_projects/project002/03_diabetes_model_reg/train/ds01_diabetes/out/bronze/ \n",
      "Validating arguments.\n",
      "Arguments validated.\n",
      "Uploading file to master/1_projects/project002/03_diabetes_model_reg/train/ds01_diabetes/out/bronze/\n",
      "Uploading an estimated of 1 files\n",
      "Uploading ./common/temp_data/project002/ds01_diabetes/Bronze\\bronze.parquet\n",
      "Uploaded ./common/temp_data/project002/ds01_diabetes/Bronze\\bronze.parquet, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n",
      "Creating new dataset\n",
      "ds02_other\n",
      "Method upload_directory: This is an experimental method, and may change at any time.<br/>For more information, see https://aka.ms/azuremlexperimental.\n",
      "Uploading to datastore: <azureml.data.azure_data_lake_datastore.AzureDataLakeGen2Datastore object at 0x000001C6D50F3CC0> \n",
      "From: ./common/temp_data/project002/ds02_other/Bronze/ \n",
      "To: master/1_projects/project002/03_diabetes_model_reg/train/ds02_other/out/bronze/ \n",
      "Validating arguments.\n",
      "Arguments validated.\n",
      "Uploading file to master/1_projects/project002/03_diabetes_model_reg/train/ds02_other/out/bronze/\n",
      "Uploading an estimated of 1 files\n",
      "Uploading ./common/temp_data/project002/ds02_other/Bronze\\bronze.parquet\n",
      "Uploaded ./common/temp_data/project002/ds02_other/Bronze\\bronze.parquet, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n",
      "Creating new dataset\n",
      "\n",
      "####### Automap & Autoregister - SUCCESS!\n",
      "1) Auto mapped 2 ESML Dataset with registered Azure ML Datasets (potentially all 3: IN,BRONZE, SILVER) in Datastore project002lake \n",
      "\n",
      "Dataset 'ds01_diabetes' status:\n",
      " - IN_Folder_has_files\n",
      " - BRONZE_Folder_has_files\n",
      " - SILVER_Folder_has_files\n",
      "Dataset 'ds02_other' status:\n",
      " - IN_Folder_has_files\n",
      " - BRONZE_Folder_has_files\n",
      " - SILVER_Folder_has_files\n",
      "\n",
      "2) Registered each Dataset with suffixes (_IN_CSV, _BRONZE, _SILVER) \n",
      " Tip: Use ESMLProject.Datasets list or .DatasetByName(myDatasetName) to read/write\n",
      "#######\n",
      "model.version 4\n",
      "Model name AutoML7094594e839 is registered.\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(os.path.abspath(\"../common/\"))  # NOQA: E402\n",
    "from esml import ESMLDataset, ESMLProject\n",
    "from baselayer_azure_ml import AutoMLFactory\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = p.get_workspace_from_config()\n",
    "\n",
    "p = ESMLProject() # Makes it \"environment aware (dev,test,prod)\", and \"configuration aware\"\n",
    "p.dev_test_prod = \"test\"\n",
    "p.init(ws) \n",
    "AutoMLFactory().register_active_model(p, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "model.version 3\nModel name AutoML7094594e839 is registered.\n"
     ]
    }
   ],
   "source": [
    "AutoMLFactory().register_active_model(p, \"test\")"
   ]
  },
  {
   "source": [
    "# ESML - accelerator\n",
    "\n",
    "## PROJECT + DATA CONCEPTS + ENTERPRISE Datalake Design + DEV->PROD MLOps\n",
    "- `1)ESML Project`: The ONLY thing you need to remember is your `Project number` (and `BRONZE, SILVER, GOLD` concept )\n",
    "    - ProjectNo=4 have a list of all your datasets as ESMLDatasets. (Well you need to provide names for them also: \"mydata01\", \"mydata02\" - but thats it)\n",
    "- `2)Lakedesign & Roles`: Bronze, silver, gold + IN and date folders\n",
    "    - Benefits: Physical datalake design!  onnected to Azure ML Workspace, with autoregistration of `Azure ML Datasets`\n",
    "    - `Role 1`: `Data ingestion team` only need to care about 1 thing - onboard data to `IN-folder`, in .CSV format\n",
    "        - `Auto parquet-conversion` from `IN` folder (.CSV) to `OUT`/BRONZE/bronze.PARQUET \n",
    "    - `Role 2`: `Data scientists` only need to care about 3 things (R/W): `BRONZE, SILVER, GOLD` datasets, all in .PARQUET format\n",
    "    - How? The ESML project will `Automap` and `Autoregister` Azure ML Datasets - `IN, SILVER, BRONZE, GOLD`\n",
    "- `2a) R&D  VS Production phase`: \"Latest data\" VS versioning on Datasets and datefolders  \n",
    "    - Benefits \"R&D mode\": Faster RnD phase to onboard and refresh data easy. Also fast \"flip-switch\" to production\n",
    "    - How? `ESMLDataset is context self aware` - knows when it is used in TRAIN or INFERENCE pipeline\n",
    "- `2b) TRAIN vs INFERENCE` versions</u> `Reuse (Bronze->Silver->Gold) pipepline`, for both TRAIN preprocessing, and INFERENCE \n",
    "    - Benefits: Inference with different MODEL version, on data from the same day/time, (to compare scoring etc)\n",
    "    - How? ESMLDataset have context self awareness, and `knows WHERE and HOW to load/save data`\n",
    "- `2c) ENTERPRISE CONFIG & PROJECT specicic`: Ajdust, per Dev,Test,Prod settings on ALL projects PERFORMANCE in Dev.\n",
    "    - Accelerate setup: `Get compute`, `Netwporkijng and private link already set`, `Datadrift, Time series traits, Smart noise, etc`\n",
    "    - `ShareBack SILVER DATA` from PROJECT to MASTER folder-lake structure: Share refined data back to its \"origin/non-projectbased structure\" easy: \n",
    "        - ESMLProject.ShareBack(ds.Silver)\n",
    "    - How? ESMProject controls all ESMDatasets, in a uniform way\n",
    "## ENTERPRISE Deployment of Models & Governance - MLOps  at scale\n",
    "- `3) DEV->TEST-PROD` (configs, compute, performance)\n",
    "    - ESML has config for 3 environemnts: Easy DEPLOY model across subscriptions and Azure ML Studio workspaces \n",
    "        - Save costs & time: \n",
    "            - `DEV` has cheaper compute performance for TRAIN and INFERENCE (batch, AKS)\n",
    "            - `DEV` has Quick-debug ML training (fast training...VS good scoring in TEST and PROD)\n",
    "        - How? ESML `AutoMLFactory` and `ComputeFactory`\n",
    "         \n",
    "\n",
    "### Q&A:\n",
    "- Q: Is ESML Machine learning specific? If I only want to refine some data...for integration, or report? \n",
    "- A: You can use this for just data refinement also: `Bronze->Silver->Gold` refinement.\n",
    "    - Benefits: Enterprise security, Read/write to datalake, easy to share refined data. \n",
    "    - Benefits: The tooling \"glued togehter\": Azure datafactory +  Azure Databricks (and Azure ML Studio pipelines if needed)\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}