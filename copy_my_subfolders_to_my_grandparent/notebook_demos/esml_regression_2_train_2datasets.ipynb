{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('azure_automl': conda)"
  },
  "interpreter": {
   "hash": "3fec2c5a411dce07235ef28c8752b6cecf1f94423de7e7c24e62fc38b1bc47de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# ESML - accelerator: Quick DEMO\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"../azure-enterprise-scale-ml/esml/common/\"))  # NOQA: E402\n",
    "from esml import ESMLDataset, ESMLProject\n",
    "p = ESMLProject() # Will search in ROOT for your copied SETTINGS folder '../../../settings', you should copy template settings from '../settings'\n",
    "p.inference_mode = False # We want \"TRAIN\" mode in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using GEN2 as Datastore\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_default_keyvault'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-02e4f749bdbc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munregister_all_datasets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mws\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# For DEMO purpose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\jostrm\\OneDrive - Microsoft\\0_GIT\\2_My\\github\\azure-enterprise-scale-ml\\azure-enterprise-scale-ml\\esml\\common\\esml.py\u001b[0m in \u001b[0;36munregister_all_datasets\u001b[1;34m(self, ws)\u001b[0m\n\u001b[0;32m   1500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1501\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0munregister_all_datasets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mws\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1502\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_lake_as_datastore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mws\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1503\u001b[0m         \u001b[0mold_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minference_mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1504\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jostrm\\OneDrive - Microsoft\\0_GIT\\2_My\\github\\azure-enterprise-scale-ml\\azure-enterprise-scale-ml\\esml\\common\\esml.py\u001b[0m in \u001b[0;36mset_lake_as_datastore\u001b[1;34m(self, ws)\u001b[0m\n\u001b[0;32m    575\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatastore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlake_access\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetBlobAsDatastore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 577\u001b[1;33m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatastore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlake_access\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetLakeAsDatastore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    578\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatastore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jostrm\\OneDrive - Microsoft\\0_GIT\\2_My\\github\\azure-enterprise-scale-ml\\azure-enterprise-scale-ml\\esml\\common\\storage_factory.py\u001b[0m in \u001b[0;36mGetLakeAsDatastore\u001b[1;34m(self, setAsDefault)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mexternal_kv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtenantId\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAzureBase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_external_keyvault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mws\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msp_id_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msp_secret_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtenant\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m         \u001b[0mfile_system_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage_config\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lake_fs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jostrm\\OneDrive - Microsoft\\0_GIT\\2_My\\github\\azure-enterprise-scale-ml\\azure-enterprise-scale-ml\\esml\\common\\baselayer_azure.py\u001b[0m in \u001b[0;36mget_external_keyvault\u001b[1;34m(ws, sp_id_key, sp_secret_key, tenant_key, external_keyvault_url)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_external_keyvault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mws\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msp_id_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msp_secret_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtenant_key\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mexternal_keyvault_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mkeyvault\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mws\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_keyvault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0mtenantId\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeyvault\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_secret\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtenant_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mcredential\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mClientSecretCredential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtenantId\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeyvault\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_secret\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msp_id_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeyvault\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_secret\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msp_secret_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_default_keyvault'"
     ]
    }
   ],
   "source": [
    "p.unregister_all_datasets(p.ws) # For DEMO purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Inference version: 1\n\n - ds01_diabetes\nprojects/project002/03_diabetes_model_reg/train/ds01_diabetes/in/dev/2021/01/01/\nprojects/project002/03_diabetes_model_reg/train/ds01_diabetes/out/bronze/dev/\nprojects/project002/03_diabetes_model_reg/train/ds01_diabetes/out/silver/dev/\n\n - ds02_other\nprojects/project002/03_diabetes_model_reg/train/ds02_other/in/dev/2021/01/01/\nprojects/project002/03_diabetes_model_reg/train/ds02_other/out/bronze/dev/\nprojects/project002/03_diabetes_model_reg/train/ds02_other/out/silver/dev/\n \n\nTraining GOLD (p.GoldPath)\nprojects/project002/03_diabetes_model_reg/train/gold/dev/\n \n\n[A) USAGE]: to_score_folder, scored_folder, date_folder = p.get_gold_scored_unique_path()\nA)INFERENCE ONLINE: GOLD to score (example if realtime - today)\nprojects/project002/03_diabetes_model_reg/inference/1/gold/dev/2021_06_21/9d6c3895a8af43f1ad4e6b75604b2168/\n \n\nA)INFERENCE ONLINE: GOLD scored (example if realtime today)\nprojects/project002/03_diabetes_model_reg/inference/1/scored/dev/2021_06_21/9d6c3895a8af43f1ad4e6b75604b2168/\n \n\n[B) USAGE]: to_score_folder_batch, scored_folder, date_folder = p.get_gold_scored_unique_path(p.date_scoring_folder)\nB)INFERENCE BATCH: GOLD to score (example batch, datetime from config)\nprojects/project002/03_diabetes_model_reg/inference/1/gold/dev/2021_06_08/f09ac3cbdfd04ec6a879c31441766940/\n \n\nB)INFERENCE BATCH: GOLD scored (example batch, datetime from config)\nprojects/project002/03_diabetes_model_reg/inference/1/scored/dev/2021_06_08/f09ac3cbdfd04ec6a879c31441766940/\n \n\nC) INFERENCE BATCH (SCENARIO 2): TODAY I scored data from X days AGO  (second datefolder from config - X days ago)\nprojects/project002/03_diabetes_model_reg/inference/1/gold/dev/2021_06_08/f09ac3cbdfd04ec6a879c31441766940/2021_06_08/\nprojects/project002/03_diabetes_model_reg/inference/1/scored/dev/2021_06_08/f09ac3cbdfd04ec6a879c31441766940/2021_06_08/\n \n\nENVIRONMENT - DEV, TEST, or PROD?  [USAGE: p.dev_test_prod]\nACTIVE ENVIRONMENT = dev\nACTIVE subscription = ca0a8c40-b06a-4e4e-8434-63c03a1dee34\n- MSFT-WEU-EAP_PROJECT02_AI-DEV-RG\n- msft-weu-DEV-eap-proj02_ai-amls\n- westeurope\n- MSFT-WEU-EAP_CMN_AI-DEV-RG\nActive vNet: msft-weu-dev-cmnai-vnet\nActive SubNet: \n[USAGE] for the above: p.vNetForActiveEnvironment()\nActive Lake (storage account)  msftweudevcmnai2\n[USAGE] for the above: p.getLakeForActiveEnvironment()\nAML for docker: True\n"
     ]
    }
   ],
   "source": [
    "#p.dev_test_prod = \"dev\"\n",
    "p.describe()"
   ]
  },
  {
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "auth = InteractiveLoginAuthentication(tenant_id = p.tenant)\n",
    "ws = Workspace.get(name = p.workspace_name,subscription_id = p.subscription_id,resource_group = p.resource_group,auth=auth)\n",
    "ws.write_config(path=\".\", file_name=\"../../ws_config.json\")\n",
    "\n",
    "ws = Workspace.from_config(\"../ws_config.json\") # Reads config.json "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 2) ESML will Automap and Autoregister Azure ML Datasets - IN, SILVER, BRONZE, GOLD\n",
    "- `Automap` and `Autoregister` Azure ML Datasets as: `IN, SILVER, BRONZE, GOLD`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'msft-weu-DEV-eap-proj02_ai-amls'"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "ws, config_name = p.authenticate_workspace_and_write_config()\n",
    "ws = p.get_workspace_from_config()\n",
    "ws.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Are we in R&D state (no dataset versioning) = False\n"
     ]
    }
   ],
   "source": [
    "print(\"Are we in R&D state (no dataset versioning) = {}\".format(p.rnd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "...\n",
      "Using GEN2 as Datastore\n",
      "Searching for setting in ESML datalake...\n",
      "ESML in-folder settings override = TRUE \n",
      " - Found settings in the ESML AutoLake  [active_in_folder.json,active_scoring_in_folder.json], to override ArgParse/GIT config with.\n",
      " - TRAIN in date:  2021/01/01\n",
      " - INFERENCE in date: 2021/06/08 and ModelVersion to score with: 1 (0=latest)\n",
      "\n",
      "Inference mode (False = Training mode): False\n",
      "Load data as Datasets....\n",
      "ds01_diabetes\n",
      "ds02_other\n",
      "\n",
      "####### Automap & Autoregister - SUCCESS!\n",
      "1) Auto mapped 2 ESML Dataset with registered Azure ML Datasets (potentially all 3: IN,BRONZE, SILVER) in Datastore project002 \n",
      "\n",
      "Dataset 'ds01_diabetes' status:\n",
      " - IN_Folder_has_files\n",
      " - BRONZE_Folder_has_files\n",
      " - SILVER_Folder_has_files\n",
      "Dataset 'ds02_other' status:\n",
      " - IN_Folder_has_files\n",
      " - BRONZE_Folder_has_files\n",
      " - SILVER_Folder_has_files\n",
      "\n",
      "2) Registered each Dataset with suffixes (_IN, _BRONZE, _SILVER) \n",
      " Tip: Use ESMLProject.Datasets list or .DatasetByName(myDatasetName) to read/write\n",
      "#######\n"
     ]
    }
   ],
   "source": [
    "datastore = p.init(ws)"
   ]
  },
  {
   "source": [
    "# 3) IN->`BRONZE->SILVER`->Gold\n",
    "- Create dataset from PANDAS - Save to SILVER"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        AGE       SEX       BMI        BP        S1        S2        S3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         S4        S5        S6      Y  \n",
       "0 -0.002592  0.019908 -0.017646  151.0  \n",
       "1 -0.039493 -0.068330 -0.092204   75.0  \n",
       "2 -0.002592  0.002864 -0.025930  141.0  \n",
       "3  0.034309  0.022692 -0.009362  206.0  \n",
       "4 -0.002592 -0.031991 -0.046641  135.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AGE</th>\n      <th>SEX</th>\n      <th>BMI</th>\n      <th>BP</th>\n      <th>S1</th>\n      <th>S2</th>\n      <th>S3</th>\n      <th>S4</th>\n      <th>S5</th>\n      <th>S6</th>\n      <th>Y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.038076</td>\n      <td>0.050680</td>\n      <td>0.061696</td>\n      <td>0.021872</td>\n      <td>-0.044223</td>\n      <td>-0.034821</td>\n      <td>-0.043401</td>\n      <td>-0.002592</td>\n      <td>0.019908</td>\n      <td>-0.017646</td>\n      <td>151.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.001882</td>\n      <td>-0.044642</td>\n      <td>-0.051474</td>\n      <td>-0.026328</td>\n      <td>-0.008449</td>\n      <td>-0.019163</td>\n      <td>0.074412</td>\n      <td>-0.039493</td>\n      <td>-0.068330</td>\n      <td>-0.092204</td>\n      <td>75.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.085299</td>\n      <td>0.050680</td>\n      <td>0.044451</td>\n      <td>-0.005671</td>\n      <td>-0.045599</td>\n      <td>-0.034194</td>\n      <td>-0.032356</td>\n      <td>-0.002592</td>\n      <td>0.002864</td>\n      <td>-0.025930</td>\n      <td>141.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.089063</td>\n      <td>-0.044642</td>\n      <td>-0.011595</td>\n      <td>-0.036656</td>\n      <td>0.012191</td>\n      <td>0.024991</td>\n      <td>-0.036038</td>\n      <td>0.034309</td>\n      <td>0.022692</td>\n      <td>-0.009362</td>\n      <td>206.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.005383</td>\n      <td>-0.044642</td>\n      <td>-0.036385</td>\n      <td>0.021872</td>\n      <td>0.003935</td>\n      <td>0.015596</td>\n      <td>0.008142</td>\n      <td>-0.002592</td>\n      <td>-0.031991</td>\n      <td>-0.046641</td>\n      <td>135.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "import pandas as pd \n",
    "ds = p.DatasetByName(\"ds01_diabetes\")\n",
    "df = ds.Bronze.to_pandas_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "## 3) BRONZE-SILVER (EDIT rows & SAVE)\n",
    "- Test change rows, same structure = new version (and new file added)\n",
    "- Note: not earlier files in folder are removed. They are needed for other \"versions\". \n",
    "- Expected: For 3 files: New version, 997 rows: 2 older files=627 + 1 new file=370\n",
    "- Expected (if we delete OLD files): New version, with less rows. 370 instead of 997"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "442 185\n"
     ]
    }
   ],
   "source": [
    "df_filtered = df[df.AGE > 0.015]\n",
    "print(df.shape[0], df_filtered.shape[0])"
   ]
  },
  {
   "source": [
    "## 3a) Save `SILVER` ds01_diabetes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'M03_ds01_diabetes_train_SILVER'"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "aml_silver = p.save_silver(p.DatasetByName(\"ds01_diabetes\"),df_filtered)\n",
    "aml_silver.name"
   ]
  },
  {
   "source": [
    "### COMPARE `BRONZE vs SILVER`\n",
    "- Compare and validate the feature engineering"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Bronze: 442\nSilver: 185\n"
     ]
    }
   ],
   "source": [
    "ds01 = p.DatasetByName(\"ds01_diabetes\")\n",
    "bronze_rows = ds01.Bronze.to_pandas_dataframe().shape[0]\n",
    "silver_rows = ds01.Silver.to_pandas_dataframe().shape[0]\n",
    "\n",
    "print(\"Bronze: {}\".format(bronze_rows)) # Expected 442 rows\n",
    "print(\"Silver: {}\".format(silver_rows)) # Expected 185 rows (filtered)\n",
    "\n",
    "assert bronze_rows == 442,\"BRONZE Should have 442 rows to start with, but is {}\".format(bronze_rows)\n",
    "assert silver_rows == 185,\"SILVER should have 185 after filtering, but is {}\".format(silver_rows)"
   ]
  },
  {
   "source": [
    "## 3b) Save  `BRONZE â†’  SILVER` ds02_other"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'M03_ds02_other_train_SILVER'"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "df_edited = p.DatasetByName(\"ds02_other\").Silver.to_pandas_dataframe()\n",
    "ds02_silver = p.save_silver(p.DatasetByName(\"ds02_other\"),df_edited)\n",
    "ds02_silver.name"
   ]
  },
  {
   "source": [
    "## 3c) Merge all `SILVERS -> then save GOLD`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Diabetes shape:  (185, 11)\n(185, 19)\n"
     ]
    }
   ],
   "source": [
    "df_01 = ds01.Silver.to_pandas_dataframe()\n",
    "df_02 = ds02_silver.to_pandas_dataframe()\n",
    "df_gold1_join = df_01.join(df_02) # left join -> NULL on df_02\n",
    "print(\"Diabetes shape: \", df_01.shape)\n",
    "print(df_gold1_join.shape)"
   ]
  },
  {
   "source": [
    "# Save `GOLD` v1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.rnd=False # Allow versioning on DATASETS, to have lineage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_gold_v1 = p.save_gold(df_gold1_join)"
   ]
  },
  {
   "source": [
    "### 3c) Ops! \"faulty\" GOLD - too many features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(185, 19)\n"
     ]
    }
   ],
   "source": [
    "print(p.Gold.to_pandas_dataframe().shape) # 19 features...I want 11"
   ]
  },
  {
   "source": [
    "print(\"Are we in RnD phase? Or do we have 'versioning on datasets=ON'\")\n",
    "print(\"RnD phase = {}\".format(p.rnd))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 36,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Are we in RnD phase? Or do we have 'versioning on datasets=ON'\nRnD phase = False\n"
     ]
    }
   ]
  },
  {
   "source": [
    "# Save `GOLD` v2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets just go with features from ds01\n",
    "ds_gold_v1 = p.save_gold(df_01)"
   ]
  },
  {
   "source": [
    "# Get `GOLD` by version"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "gold_1 = p.get_gold_version(1)\n",
    "gold_1.to_pandas_dataframe().shape # (185, 19)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 38,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(185, 19)"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(185, 11)"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "gold_2 = p.get_gold_version(2)\n",
    "gold_2.to_pandas_dataframe().shape # (185, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(185, 11)"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "p.Gold.to_pandas_dataframe().shape # Latest version (185, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01_filtered = df_01[df_01.AGE > 0.03807]\n",
    "ds_gold_v1 = p.save_gold(df_01_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(113, 11)"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "gold_2 = p.get_gold_version(3) # sliced, from latest version\n",
    "gold_2.to_pandas_dataframe().shape # (113, 11)"
   ]
  },
  {
   "source": [
    "# TRAIN - `AutoMLFactory + ComputeFactory`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baselayer_azure_ml import AutoMLFactory, ComputeFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "what environment are we targeting? =  test\n"
     ]
    }
   ],
   "source": [
    "p.dev_test_prod = \"test\"\n",
    "print(\"what environment are we targeting? =  {}\".format(p.dev_test_prod)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading AutoML config settings from: test\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'enable_voting_ensemble': True,\n",
       " 'enable_stack_ensemble': True,\n",
       " 'model_explainability': True,\n",
       " 'experiment_timeout_hours': 24,\n",
       " 'iteration_timeout_minutes': 480,\n",
       " 'n_cross_validations': 9,\n",
       " 'enable_early_stopping': True,\n",
       " 'iterations': 1000,\n",
       " 'max_cores_per_iteration': -1,\n",
       " 'allowed_models': ['LightGBM'],\n",
       " 'blocked_models': ['GradientBoosting',\n",
       "  'XGBoostRegressor',\n",
       "  'ExtremeRandomTrees',\n",
       "  'LassoLars',\n",
       "  'RandomForest',\n",
       "  'ElasticNet',\n",
       "  'AutoArima'],\n",
       " 'path': '.',\n",
       " 'debug_log': 'azure_automl_debug_test.log'}"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "automl_performance_config = p.get_automl_performance_config()\n",
    "automl_performance_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading AutoML config settings from: dev\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'enable_voting_ensemble': False,\n",
       " 'enable_stack_ensemble': False,\n",
       " 'model_explainability': True,\n",
       " 'experiment_timeout_hours': 0.25,\n",
       " 'iteration_timeout_minutes': 2,\n",
       " 'n_cross_validations': 2,\n",
       " 'enable_early_stopping': True,\n",
       " 'iterations': 20,\n",
       " 'max_cores_per_iteration': -1,\n",
       " 'allowed_models': ['LightGBM'],\n",
       " 'path': '.',\n",
       " 'debug_log': 'azure_automl_debug_dev.log'}"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "p.dev_test_prod = \"dev\"\n",
    "automl_performance_config = p.get_automl_performance_config()\n",
    "automl_performance_config"
   ]
  },
  {
   "source": [
    "# Get `COMPUTE` for current `ENVIRONMENT`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Note: OVERRIDING enterprise performance settings with project specifics. (to change, set flag in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=False)\n",
      "Using a model specific cluster, per configuration in project specific settings, (the integer of 'model_number' is the base for the name)\n",
      "Note: OVERRIDING enterprise performance settings with project specifics. (to change, set flag in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=False)\n",
      "Found existing cluster prj02-m03-dev for project and environment, using it.\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n",
      "image_build_compute = prj02-m03-dev\n"
     ]
    }
   ],
   "source": [
    "aml_compute = p.get_training_aml_compute(ws)"
   ]
  },
  {
   "source": [
    "# `TRAIN` model -> See other notebook `esml_howto_2_train.ipynb`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute '_auth'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-0519e6c8d24c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Y\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtrain_6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_set_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_set_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit_gold_3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Auto-registerin AZURE (M03_GOLD_TRAIN | M03_GOLD_VALIDATE | M03_GOLD_TEST) # Alt: train,testv= p.Gold.random_split(percentage=0.8, seed=23)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m automl_config = AutoMLConfig(task = 'regression',\n\u001b[0;32m      7\u001b[0m                              \u001b[0mprimary_metric\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mazure_metric_regression\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMAE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jostrm\\OneDrive - Microsoft\\0_GIT\\2_My\\github\\azure-enterprise-scale-ml\\azure-enterprise-scale-ml\\esml\\common\\esml.py\u001b[0m in \u001b[0;36msplit_gold_3\u001b[1;34m(self, train_percentage, label, new_version, seed)\u001b[0m\n\u001b[0;32m   1261\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msplit_gold_3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_percentage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnew_version\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1263\u001b[1;33m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pandas_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1264\u001b[0m         \u001b[0mwhats_left_for_both\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtrain_percentage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 0.4 ...0.3 if 70%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m         \u001b[0mleft_per_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwhats_left_for_both\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 0.2  ...0.15\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\jostrm\\OneDrive - Microsoft\\0_GIT\\2_My\\github\\azure-enterprise-scale-ml\\azure-enterprise-scale-ml\\esml\\common\\esml.py\u001b[0m in \u001b[0;36mGold\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gold_dataset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# Lazy load 1st version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gold_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mws\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_gold_name_azure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gold_dataset\u001b[0m \u001b[1;31m# Latest version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mUserErrorException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\azure_automl\\lib\\site-packages\\azureml\\data\\_loggerfactory.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0m_LoggerFactory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrack_activity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivity_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_dimensions\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mal\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'activity_info'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'error_code'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\azure_automl\\lib\\site-packages\\azureml\\data\\abstract_dataset.py\u001b[0m in \u001b[0;36mget_by_name\u001b[1;34m(workspace, name, version)\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtyping\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mazureml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTabularDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mazureml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFileDataset\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \"\"\"\n\u001b[1;32m---> 89\u001b[1;33m         \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAbstractDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m         \u001b[0mAbstractDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_track_lineage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\azure_automl\\lib\\site-packages\\azureml\\data\\abstract_dataset.py\u001b[0m in \u001b[0;36m_get_by_name\u001b[1;34m(workspace, name, version)\u001b[0m\n\u001b[0;32m    651\u001b[0m         \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_make_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    652\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 653\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    654\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_dto_to_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    655\u001b[0m         \u001b[0mwarn_deprecated_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\azure_automl\\lib\\site-packages\\azureml\\data\\_dataset_rest_helper.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(request_fn, handle_error_fn)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mHttpOperationError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\azure_automl\\lib\\site-packages\\azureml\\data\\abstract_dataset.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m()\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m             dto = _restclient(workspace).dataset.get_dataset_by_name(\n\u001b[0m\u001b[0;32m    636\u001b[0m                 \u001b[0mworkspace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubscription_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m                 \u001b[0mworkspace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresource_group\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\azure_automl\\lib\\site-packages\\azureml\\data\\_dataset_rest_helper.py\u001b[0m in \u001b[0;36m_restclient\u001b[1;34m(ws)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_restclient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mws\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[0mhost_env\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'AZUREML_SERVICE_ENDPOINT'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m     \u001b[0mauth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mws\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_auth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mazureml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_base_sdk_common\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice_discovery\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_service_url\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute '_auth'"
     ]
    }
   ],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "from baselayer_azure_ml import azure_metric_regression\n",
    "\n",
    "label = \"Y\"\n",
    "train_6, validate_set_2, test_set_2 = p.split_gold_3(0.6,label) # Auto-registerin AZURE (M03_GOLD_TRAIN | M03_GOLD_VALIDATE | M03_GOLD_TEST) # Alt: train,testv= p.Gold.random_split(percentage=0.8, seed=23)\n",
    "automl_config = AutoMLConfig(task = 'regression',\n",
    "                             primary_metric = azure_metric_regression.MAE,\n",
    "                             compute_target = aml_compute,\n",
    "                             training_data = p.GoldTrain, # is 'train_6' pandas dataframe, but as an Azure ML Dataset\n",
    "                             label_column_name = label,\n",
    "                             experiment_exit_score = '0.308', # DEMO purpose\n",
    "                             **automl_performance_config\n",
    "                            )\n",
    "\n",
    "via_pipeline = False\n",
    "best_run, fitted_model, experiment = AutoMLFactory(p).train_pipeline(automl_config) if via_pipeline else AutoMLFactory(p).train_as_run(automl_config)"
   ]
  },
  {
   "source": [
    "# END"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# ESML - accelerator\n",
    "\n",
    "## PROJECT + DATA CONCEPTS + ENTERPRISE Datalake Design + DEV->PROD MLOps\n",
    "- `1)ESML Project`: The ONLY thing you need to remember is your `Project number` (and `BRONZE, SILVER, GOLD` concept )\n",
    "    - ProjectNo=4 have a list of all your datasets as ESMLDatasets. (Well you need to provide names for them also: \"mydata01\", \"mydata02\" - but thats it)\n",
    "- `2)Lakedesign & Roles`: Bronze, silver, gold + IN and date folders\n",
    "    - Benefits: Physical datalake design!  onnected to Azure ML Workspace, with autoregistration of `Azure ML Datasets`\n",
    "    - `Role 1`: `Data ingestion team` only need to care about 1 thing - onboard data to `IN-folder`, in .CSV format\n",
    "        - `Auto parquet-conversion` from `IN` folder (.CSV) to `OUT`/BRONZE/bronze.PARQUET \n",
    "    - `Role 2`: `Data scientists` only need to care about 3 things (R/W): `BRONZE, SILVER, GOLD` datasets, all in .PARQUET format\n",
    "    - How? The ESML project will `Automap` and `Autoregister` Azure ML Datasets - `IN, SILVER, BRONZE, GOLD`\n",
    "- `2a) R&D  VS Production phase`: \"Latest data\" VS versioning on Datasets and datefolders  \n",
    "    - Benefits \"R&D mode\": Faster RnD phase to onboard and refresh data easy. Also fast \"flip-switch\" to production\n",
    "    - How? `ESMLDataset is context self aware` - knows when it is used in TRAIN or INFERENCE pipeline\n",
    "- `2b) TRAIN vs INFERENCE` versions</u> `Reuse (Bronze->Silver->Gold) pipepline`, for both TRAIN preprocessing, and INFERENCE \n",
    "    - Benefits: Inference with different MODEL version, on data from the same day/time, (to compare scoring etc)\n",
    "    - How? ESMLDataset have context self awareness, and `knows WHERE and HOW to load/save data`\n",
    "- `2c) BATCH CONFIG`: Turn on/off features on ALL datasets\n",
    "    - Accelerate setup: `Datadrift, Time series traits, Smart noise, etc`\n",
    "    - Share refined data back to its \"origin/non-projectbased structure\" easy: \n",
    "        - ESMLProject.ShareBack(ds.Silver)\n",
    "    - How? ESMProject controls all ESMDatasets, in a uniform way\n",
    "## ENTERPRISE Deployment of Models & Governance - MLOps  at scale\n",
    "- `3) DEV->TEST-PROD` (configs, compute, performance)\n",
    "    - ESML has config for 3 environemnts: Easy DEPLOY model across subscriptions and Azure ML Studio workspaces \n",
    "        - Save costs & time: \n",
    "            - `DEV` has cheaper compute performance for TRAIN and INFERENCE (batch, AKS)\n",
    "            - `DEV` has Quick-debug ML training (fast training...VS good scoring in TEST and PROD)\n",
    "        - How? ESML `AutoMLFactory` and `ComputeFactory`\n",
    "         \n",
    "\n",
    "### Q&A:\n",
    "- Q: Is ESML Machine learning specific? If I only want to refine some data...for integration, or report? \n",
    "- A: You can use this for just data refinement also: `Bronze->Silver->Gold` refinement.\n",
    "    - Benefits: Enterprise security, Read/write to datalake, easy to share refined data. \n",
    "    - Benefits: The tooling \"glued togehter\": Azure datafactory +  Azure Databricks (and Azure ML Studio pipelines if needed)\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'dev'"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "p.dev_test_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Example: If new model scores better in DEV, we can promote this to TEST\n",
      "Loading AutoML config settings from: dev\n",
      "targe=source environement. Compare model version in DEV/TEST/PROD with latest registered in same DEV/TEST/PROD workspace (same workspace & subscriptiom comparison)\n",
      "WARNING:root:The version of the SDK does not match the version the model was trained on.\n",
      "WARNING:root:The consistency in the result may not be guaranteed.\n",
      "WARNING:root:Package:azureml-automl-core, training version:1.27.0, current version:1.26.0\n",
      "Package:azureml-automl-runtime, training version:1.27.0.post2, current version:1.26.0\n",
      "Package:azureml-core, training version:1.27.0, current version:1.26.0\n",
      "Package:azureml-dataprep, training version:2.14.2, current version:2.13.2\n",
      "Package:azureml-dataprep-native, training version:33.0.0, current version:32.0.0\n",
      "Package:azureml-dataprep-rslex, training version:1.12.1, current version:1.11.2\n",
      "Package:azureml-dataset-runtime, training version:1.27.0, current version:1.26.0\n",
      "Package:azureml-defaults, training version:1.27.0, current version:1.26.0\n",
      "Package:azureml-interpret, training version:1.27.0, current version:1.26.0\n",
      "Package:azureml-pipeline-core, training version:1.27.0, current version:1.26.0\n",
      "Package:azureml-telemetry, training version:1.27.0, current version:1.26.0\n",
      "Package:azureml-train-automl-client, training version:1.27.0, current version:1.26.0\n",
      "Package:azureml-train-automl-runtime, training version:1.27.0.post1, current version:1.26.0\n",
      "WARNING:root:Below packages were used for model training but missing in current environment:\n",
      "WARNING:root:Package:azureml-mlflow, training version:1.27.0\n",
      "WARNING:root:Please ensure the version of your local conda dependencies match the version on which your model was trained in order to properly retrieve your model.\n",
      "MAPE (Mean average Percentage Error): 40.71997400633626\n",
      "MAE (normalized_mean_absolute_error): 0.1989748004357922\n",
      "R2 (r2_score): 0.16007651733590983\n",
      "Spearman (spearman_correlation): 0.5085746395647649\n",
      "TARGET is in the same Azure ML Studio workspace as SOURCE, comparing with latest registered model...\n",
      "target_best_run_id AutoML_4e4e4338-c417-4b80-9899-92e36d8005de\n",
      "WARNING:root:The version of the SDK does not match the version the model was trained on.\n",
      "WARNING:root:The consistency in the result may not be guaranteed.\n",
      "WARNING:root:Package:azureml-automl-core, training version:1.27.0, current version:1.26.0\n",
      "Package:azureml-automl-runtime, training version:1.27.0.post2, current version:1.26.0\n",
      "Package:azureml-core, training version:1.27.0, current version:1.26.0\n",
      "Package:azureml-dataprep, training version:2.14.2, current version:2.13.2\n",
      "Package:azureml-dataprep-native, training version:33.0.0, current version:32.0.0\n",
      "Package:azureml-dataprep-rslex, training version:1.12.1, current version:1.11.2\n",
      "Package:azureml-dataset-runtime, training version:1.27.0, current version:1.26.0\n",
      "Package:azureml-defaults, training version:1.27.0, current version:1.26.0\n",
      "Package:azureml-interpret, training version:1.27.0, current version:1.26.0\n",
      "Package:azureml-pipeline-core, training version:1.27.0, current version:1.26.0\n",
      "Package:azureml-telemetry, training version:1.27.0, current version:1.26.0\n",
      "Package:azureml-train-automl-client, training version:1.27.0, current version:1.26.0\n",
      "Package:azureml-train-automl-runtime, training version:1.27.0.post1, current version:1.26.0\n",
      "WARNING:root:Below packages were used for model training but missing in current environment:\n",
      "WARNING:root:Package:azureml-mlflow, training version:1.27.0\n",
      "WARNING:root:Please ensure the version of your local conda dependencies match the version on which your model was trained in order to properly retrieve your model.\n",
      "MAPE (Mean average Percentage Error): 37.36539689710541\n",
      "MAE (normalized_mean_absolute_error): 0.1641754076941266\n",
      "R2 (r2_score): 0.46617256831419573\n",
      "Spearman (spearman_correlation): 0.6726695514799195\n",
      "Current Production model normalized mean mse: 0.1641754076941266, New trained model mse: 0.1989748004357922\n",
      "\n",
      "OBS! 'debug_always_promote_model' config-flag active - new model will probably always perform better, added +10 to all errors on ACTIVE model at comparison\n",
      "New trained model 0.1989748004357922 performs better in MAE compared to old 10.164175407694126\n",
      "New trained model performs better in R2, thus it will be registered\n",
      "New trained model performs better in MAPE and are >= in R2 and SPEARMAN correlation, thus it is promoted to be registered\n",
      "\n",
      "Promote model?  True\n",
      "New Model: AutoML31ef0ccb01 in environment dev\n",
      "Existing Model: AutoML4e4e4338c0 in environment dev\n",
      "Loading AutoML config settings from: dev\n",
      "Loading AutoML config settings from: dev\n",
      "model.version 1\n",
      "Model name AutoML31ef0ccb01 is registered.\n"
     ]
    }
   ],
   "source": [
    "from baselayer_azure_ml import AutoMLFactory\n",
    "target_env = p.dev_test_prod #\"dev\", test, prod  = Target environment. Does Model A score better than Model B?\n",
    "print(\"Example: If new model scores better in DEV, we can promote this to TEST\")\n",
    "\n",
    "promote, m1_name, r1_id, m2_name, r2_run_id = AutoMLFactory(p).compare_scoring_current_vs_new_model(target_env)\n",
    "\n",
    "print(\"Promote model?  {}\".format(promote))\n",
    "print(\"New Model: {} in environment {}\".format(m1_name, p.dev_test_prod))\n",
    "print(\"Existing Model: {} in environment {}\".format(m2_name,target_env))\n",
    "\n",
    "if (promote and p.dev_test_prod == target_env):# Can only register a model in same workspace (test->test) - need to retrain if going from dev->test\n",
    "    AutoMLFactory(p).register_active_model(target_env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading AutoML config settings from: dev\n",
      "Loading AutoML config settings from: dev\n",
      "WARNING:root:The version of the SDK does not match the version the model was trained on.\n",
      "WARNING:root:The consistency in the result may not be guaranteed.\n",
      "WARNING:root:Package:azureml-automl-core, training version:1.27.0, current version:1.26.0\n",
      "Package:azureml-automl-runtime, training version:1.27.0.post2, current version:1.26.0\n",
      "Package:azureml-core, training version:1.27.0, current version:1.26.0\n",
      "Package:azureml-dataprep, training version:2.14.2, current version:2.13.2\n",
      "Package:azureml-dataprep-native, training version:33.0.0, current version:32.0.0\n",
      "Package:azureml-dataprep-rslex, training version:1.12.1, current version:1.11.2\n",
      "Package:azureml-dataset-runtime, training version:1.27.0, current version:1.26.0\n",
      "Package:azureml-defaults, training version:1.27.0, current version:1.26.0\n",
      "Package:azureml-interpret, training version:1.27.0, current version:1.26.0\n",
      "Package:azureml-pipeline-core, training version:1.27.0, current version:1.26.0\n",
      "Package:azureml-telemetry, training version:1.27.0, current version:1.26.0\n",
      "Package:azureml-train-automl-client, training version:1.27.0, current version:1.26.0\n",
      "Package:azureml-train-automl-runtime, training version:1.27.0.post1, current version:1.26.0\n",
      "WARNING:root:Below packages were used for model training but missing in current environment:\n",
      "WARNING:root:Package:azureml-mlflow, training version:1.27.0\n",
      "WARNING:root:Please ensure the version of your local conda dependencies match the version on which your model was trained in order to properly retrieve your model.\n",
      "Deploying model: AutoML31ef0ccb01 with verison: 1 to environment: dev with overwrite_endpoint=True\n",
      "Note: OVERRIDING enterprise performance settings with project specifics. (to change, set flag in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=False)\n",
      "image_build_compute = prj02-m03-dev\n",
      "Found existing AksWebservice endpoint, deleting it, since overwrite=True\n",
      "Note: OVERRIDING enterprise performance settings with project specifics. (to change, set flag in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=False)\n",
      "Found existing cluster, esml-dev-prj02, using it.\n",
      "Note: Autoscale_enabled=False, or since aks_dev_test=True in config, autoscaling is automatically shut off, e.g. overridden in config (since not supported) for environment dev\n",
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-05-10 22:37:51+02:00 Creating Container Registry if not exists.\n",
      "2021-05-10 22:37:51+02:00 Registering the environment.\n",
      "2021-05-10 22:37:52+02:00 Use the existing image.\n",
      "2021-05-10 22:37:54+02:00 Creating resources in AKS.\n",
      "2021-05-10 22:37:55+02:00 Submitting deployment to compute.\n",
      "2021-05-10 22:37:55+02:00 Checking the status of deployment esml-dev-p02-m03-aksapi..\n",
      "2021-05-10 22:38:08+02:00 Checking the status of inference endpoint esml-dev-p02-m03-aksapi.\n",
      "Succeeded\n",
      "AKS service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n",
      "2021-05-10T20:38:01,784940118+00:00 - rsyslog/run \n",
      "2021-05-10T20:38:01,786187503+00:00 - gunicorn/run \n",
      "rsyslogd: /azureml-envs/azureml_98cae94c606e3ceb655a787040a8a93c/lib/libuuid.so.1: no version information available (required by rsyslogd)\n",
      "2021-05-10T20:38:01,799104244+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_98cae94c606e3ceb655a787040a8a93c/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_98cae94c606e3ceb655a787040a8a93c/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_98cae94c606e3ceb655a787040a8a93c/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_98cae94c606e3ceb655a787040a8a93c/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_98cae94c606e3ceb655a787040a8a93c/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "2021-05-10T20:38:01,800918121+00:00 - iot-server/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2021-05-10T20:38:01,896471144+00:00 - iot-server/finish 1 0\n",
      "2021-05-10T20:38:01,897656830+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (10)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 39\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Generating new fontManager, this may take some time...\n",
      "Initializing logger\n",
      "2021-05-10 20:38:03,088 | root | INFO | Starting up app insights client\n",
      "2021-05-10 20:38:03,088 | root | INFO | Starting up request id generator\n",
      "2021-05-10 20:38:03,088 | root | INFO | Starting up app insight hooks\n",
      "2021-05-10 20:38:03,088 | root | INFO | Invoking user's init function\n",
      "2021-05-10 20:38:05,328 | azureml.core | WARNING | Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\n",
      "2021-05-10 20:38:05,609 | root | INFO | Users's init has completed successfully\n",
      "2021-05-10 20:38:05,612 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2021-05-10 20:38:05,612 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2021-05-10 20:38:05,613 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "2021-05-10 20:38:09,094 | root | INFO | 200\n",
      "127.0.0.1 - - [10/May/2021:20:38:09 +0000] \"GET /swagger.json HTTP/1.0\" 200 2711 \"-\" \"hackney/1.17.4\"\n",
      "2021-05-10 20:38:13,236 | root | INFO | 200\n",
      "127.0.0.1 - - [10/May/2021:20:38:13 +0000] \"GET /swagger.json HTTP/1.0\" 200 2711 \"-\" \"hackney/1.17.4\"\n",
      "\n",
      "Deployed AKS Webservice: esml-dev-p02-m03-aksapi \n",
      "Webservice Uri: https://esmlcmn7skp17.westeurope.cloudapp.azure.com:443/api/v1/service/esml-dev-p02-m03-aksapi/score \n",
      "Webservice API_key are stored in keyvault with name: esml-dev-p02-m03-api \n",
      "Webservice API_URI are stored in keyvault with name: esml-dev-p02-m03-api \n",
      "Webservice Swagger Uri: https://esmlcmn7skp17.westeurope.cloudapp.azure.com:443/api/v1/service/esml-dev-p02-m03-aksapi/swagger.json\n"
     ]
    }
   ],
   "source": [
    "inference_config, model, best_run = p.get_active_model_inference_config(ws) #  AutoML support \n",
    "service,api_uri, kv_aks_api_secret= p.deploy_automl_model_to_aks(model,inference_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "M03_GOLD_VALIDATE : (23, 11)\n",
      "X_test  (23, 10)\n",
      "y_test  (23,)\n",
      "{'split_percentage': '0.2', 'label': 'Y'}\n",
      "Note: OVERRIDING enterprise performance settings with project specifics. (to change, set flag in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=False)\n",
      "Note: Fetching keys automatically via workspace keyvault.\n",
      "Saving scoring to lake for project folder project002 and inference_model_version: 1 ...\n",
      "...\n",
      "\n",
      "Saved DATA to score successfully in LAKE, as file 'to_score_my_caller_id_tracker_guid.parquet'\n",
      "Saved SCORED data in LAKE, as file 'scored_my_caller_id_tracker_guid.parquet'\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   AGE   SEX   BMI    BP    S1    S2    S3   S4    S5    S6  result\n",
       "0 0.08  0.05 -0.00 -0.03  0.04  0.06 -0.01 0.03 -0.00 -0.00  143.96\n",
       "1 0.05  0.05  0.06  0.03  0.03 -0.05 -0.05 0.07  0.13  0.14  236.46\n",
       "2 0.07 -0.04 -0.01 -0.01  0.09  0.10  0.01 0.03 -0.01  0.03  118.17\n",
       "3 0.05  0.05 -0.01  0.05  0.05 -0.02 -0.01 0.03  0.12 -0.02  177.14\n",
       "4 0.05  0.05 -0.01 -0.03 -0.01  0.00 -0.04 0.03  0.03  0.03  168.26"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AGE</th>\n      <th>SEX</th>\n      <th>BMI</th>\n      <th>BP</th>\n      <th>S1</th>\n      <th>S2</th>\n      <th>S3</th>\n      <th>S4</th>\n      <th>S5</th>\n      <th>S6</th>\n      <th>result</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.08</td>\n      <td>0.05</td>\n      <td>-0.00</td>\n      <td>-0.03</td>\n      <td>0.04</td>\n      <td>0.06</td>\n      <td>-0.01</td>\n      <td>0.03</td>\n      <td>-0.00</td>\n      <td>-0.00</td>\n      <td>143.96</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.05</td>\n      <td>0.05</td>\n      <td>0.06</td>\n      <td>0.03</td>\n      <td>0.03</td>\n      <td>-0.05</td>\n      <td>-0.05</td>\n      <td>0.07</td>\n      <td>0.13</td>\n      <td>0.14</td>\n      <td>236.46</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.07</td>\n      <td>-0.04</td>\n      <td>-0.01</td>\n      <td>-0.01</td>\n      <td>0.09</td>\n      <td>0.10</td>\n      <td>0.01</td>\n      <td>0.03</td>\n      <td>-0.01</td>\n      <td>0.03</td>\n      <td>118.17</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.05</td>\n      <td>0.05</td>\n      <td>-0.01</td>\n      <td>0.05</td>\n      <td>0.05</td>\n      <td>-0.02</td>\n      <td>-0.01</td>\n      <td>0.03</td>\n      <td>0.12</td>\n      <td>-0.02</td>\n      <td>177.14</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.05</td>\n      <td>0.05</td>\n      <td>-0.01</td>\n      <td>-0.03</td>\n      <td>-0.01</td>\n      <td>0.00</td>\n      <td>-0.04</td>\n      <td>0.03</td>\n      <td>0.03</td>\n      <td>0.03</td>\n      <td>168.26</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "X_test, y_test, tags = p.get_gold_validate_Xy() # Get the X_test data, ESML knows the SPLIT and LABEL already (due to training)\n",
    "print(tags)\n",
    "\n",
    "df = p.call_webservice(p.ws, X_test,\"my_caller_id_tracker_guid\") # Auto-fetch key from keyvault, and calls the webservice\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}